{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MRI_Image_TO_EDSS', 'rb') as f:\n",
    "    MRI_Image_TO_EDSS = pickle.load(f)\n",
    "print(len(MRI_Image_TO_EDSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_T1_post = []\n",
    "images_T1_pre = []\n",
    "images_T2 = []\n",
    "images_flair  = []\n",
    "\n",
    "labels = [] # np.array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0], dtype=np.int64)\n",
    "MRIs = []\n",
    "\n",
    "for i in range(len(MRI_Image_TO_EDSS)):\n",
    "    MRI_Image = str(int(MRI_Image_TO_EDSS[i][0]))\n",
    "    if MRI_Image not in os.listdir('./img_debias'):\n",
    "        continue\n",
    "    if len(os.listdir(os.sep.join([\"img_debias\", MRI_Image]))) != 5:\n",
    "        continue\n",
    "        \n",
    "    ### T1 Post\n",
    "    data_path_T1_post = os.sep.join([\"img_debias\", MRI_Image, \"t1_post_reg_des_debis.nii.gz\"])\n",
    "    images_T1_post.append(data_path_T1_post)\n",
    "    \n",
    "    ### T1 Pre\n",
    "    data_path_T1_pre = os.sep.join([\"img_debias\", MRI_Image, \"t1_pre_reg_des_debis.nii.gz\"])\n",
    "    images_T1_pre.append(data_path_T1_pre)\n",
    "    \n",
    "    ### T2 \n",
    "    data_path_T2 = os.sep.join([\"img_debias\", MRI_Image, \"t2_reg_des_debis.nii.gz\"])\n",
    "    images_T2.append(data_path_T2)\n",
    "\n",
    "    ### flair\n",
    "    data_path_flair= os.sep.join([\"img_debias\", MRI_Image, \"flair_reg_des_debis.nii.gz\"])\n",
    "    images_flair.append(data_path_flair)\n",
    "    \n",
    "    labels.append(int(MRI_Image_TO_EDSS[i][1] > 4.0))\n",
    "    MRIs.append(MRI_Image)\n",
    "print(len(images_T1_post), len(images_T1_pre),len(images_T2), len(images_flair), len(labels))\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "# data_path = os.sep.join([\"../../\", \"workspace\", \"data\", \"medical\", \"ixi\", \"IXI-T1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  shuffle first\n",
    "randinds = np.arange(len(labels))\n",
    "np.random.seed(42) \n",
    "np.random.shuffle(randinds)\n",
    "\n",
    "MRIs = [MRIs[i] for i in randinds]\n",
    "labels = [labels[i] for i in randinds]\n",
    "images_T1_post = [images_T1_post[i] for i in randinds]\n",
    "images_T1_pre = [images_T1_pre[i] for i in randinds]\n",
    "images_T2 = [images_T2[i] for i in randinds]\n",
    "images_flair = [images_flair[i] for i in randinds]\n",
    "\n",
    "## split train /test \n",
    "train_frac = \n",
    "Ntot = len(labels)\n",
    "\n",
    "cut = int(train_frac * Ntot)\n",
    "\n",
    "MRIs_train = MRIs[: cut]\n",
    "MRIs_test = MRIs[cut:]  \n",
    "labels_train = labels[: cut]\n",
    "labels_test = labels[cut :]\n",
    "images_T1_post_train = images_T1_post[: cut]\n",
    "images_T1_post_test = images_T1_post[cut :]\n",
    "images_T1_pre_train  = images_T1_pre[: cut]\n",
    "images_T1_pre_test  = images_T1_pre[cut :]\n",
    "images_T2_train  = images_T2[: cut]\n",
    "images_T2_test  = images_T2[cut :]\n",
    "images_flair_train = images_flair[: cut]\n",
    "images_flair_test = images_flair[cut :]\n",
    "\n",
    "## Augment train only\n",
    "inds = [i for i, x in enumerate(labels_train) if x ==1]\n",
    "MRIs_train.extend([MRIs_train[i] for i in inds]*10)\n",
    "labels_train.extend([labels_train[i] for i in inds]*10)\n",
    "images_T1_post_train.extend([images_T1_post_train[i] for i in inds]*10)\n",
    "images_T1_pre_train.extend([images_T1_pre_train[i] for i in inds]*10)\n",
    "images_T2_train.extend([images_T2_train[i] for i in inds]*10)\n",
    "images_flair_train.extend([images_flair_train[i] for i in inds]*10)\n",
    "\n",
    "##  shuffle train again\n",
    "randinds = np.arange(len(labels_train))\n",
    "np.random.seed(42) \n",
    "np.random.shuffle(randinds)\n",
    "MRIs_train = [MRIs_train[i] for i in randinds]\n",
    "labels_train = [labels_train[i] for i in randinds]\n",
    "images_T1_post_train = [images_T1_post_train[i] for i in randinds]\n",
    "images_T1_pre_train = [images_T1_pre_train[i] for i in randinds]\n",
    "images_T2_train = [images_T2_train[i] for i in randinds]\n",
    "images_flair_train = [images_flair_train[i] for i in randinds]\n",
    "\n",
    "print('====>Train set size:')\n",
    "print(len(images_T1_post_train), len(images_T1_pre_train),len(images_T2_train), \n",
    "      len(images_flair_train), len(labels_train))\n",
    "print('=======> # positives in Train')\n",
    "print(np.sum(labels_train))\n",
    "print('====>Test set size:')\n",
    "print(len(images_T1_post_test), len(images_T1_pre_test),len(images_T2_test), \n",
    "      len(images_flair_test), len(labels_test))\n",
    "print('=======> # positives in Test')\n",
    "print(np.sum(labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(MRIs_train)), len(set(MRIs_test)), \\\n",
    "len(set(MRIs_train).intersection(MRIs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set label weight  in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(labels_train))\n",
    "class_count = [np.sum(np.array(labels_train) == i ) for i in range(num_classes)]\n",
    "print(num_classes, class_count)\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(labels_train), len(labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix , auc, precision_recall_curve, average_precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    false_positive_rate, recall, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    auprc = average_precision_score(y_true, y_pred)\n",
    "    print('AUC: ',roc_auc, \"AUPRC: \", auprc)\n",
    "\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "\n",
    "    # calculate the g-mean for each threshold\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred > thresholds[ix]).ravel()\n",
    "    print('TN: ', tn, \", FP: \",fp, \", FN:\", fn, \", TP:\", tp)\n",
    "    print(\"==> Sensitivity (Recall, TPR): %.3f\"%(tp/(tp+fn)))\n",
    "    print(\"==> Specifity: %.3f\"%(tn/(tn+fp)))\n",
    "    print(\"==> Positive Predictive Value (PPV) (Precision): %.3f\"%(tp / (tp + fp)))\n",
    "    print(\"==> Negative Predictive Value (NPV): %.3f\"%(tn / (tn + fn)))\n",
    "    print(\"==> Accuracy: %.3f\"%((tp+tn)/(tn+ fp+ fn+tp)))\n",
    "    print(\"==> F1 score: %.3f\"%((2*tp)/(2*tp + fp + fn)))\n",
    "    \n",
    "    ns_probs = [0 for _ in range(len(y_true))]\n",
    "    \n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_true, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_true, y_pred)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill, AUC = %0.2f' % 0.5)\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label = 'Our model: AUC = %0.2f' % roc_auc)\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    lr_auc = auc(lr_recall, lr_precision)\n",
    "    # summarize scores\n",
    "#     print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "    # plot the precision-recall curves\n",
    "    y_true = np.array(y_true)\n",
    "    no_skill = len(y_true[y_true==1]) / len(y_true)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No skill, AUPRC = %0.2f' % no_skill)\n",
    "    plt.plot(lr_recall, lr_precision, marker='.',label = 'Our model: AUPRC = %0.2f' % auprc)\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend(loc = 'upper right')\n",
    "    # show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from typing import Callable, Sequence, Type, Union\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from monai.networks.layers.factories import Conv, Dropout, Pool\n",
    "from monai.networks.layers.utils import get_act_layer, get_norm_layer\n",
    "from monai.utils.module import look_up_option\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            in_channels: number of the input channel.\n",
    "            out_channels: number of the output classes.\n",
    "            act: activation type and arguments. Defaults to relu.\n",
    "            norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.AVG, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=in_channels))\n",
    "        self.add_module(\"relu\", get_act_layer(name=act))\n",
    "        self.add_module(\"conv\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "        self.add_module(\"pool\", pool_type(kernel_size=2, stride=2))\n",
    "\n",
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        growth_rate: int,\n",
    "        bn_size: int,\n",
    "        dropout_prob: float,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            in_channels: number of the input channel.\n",
    "            growth_rate: how many filters to add each layer (k in paper).\n",
    "            bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                (i.e. bn_size * k features in the bottleneck layer)\n",
    "            dropout_prob: dropout rate after each dense layer.\n",
    "            act: activation type and arguments. Defaults to relu.\n",
    "            norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        out_channels = bn_size * growth_rate\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        dropout_type: Callable = Dropout[Dropout.DROPOUT, spatial_dims]\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "\n",
    "        self.layers.add_module(\"norm1\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=in_channels))\n",
    "        self.layers.add_module(\"relu1\", get_act_layer(name=act))\n",
    "        self.layers.add_module(\"conv1\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "\n",
    "        self.layers.add_module(\"norm2\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=out_channels))\n",
    "        self.layers.add_module(\"relu2\", get_act_layer(name=act))\n",
    "        self.layers.add_module(\"conv2\", conv_type(out_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n",
    "\n",
    "        if dropout_prob > 0:\n",
    "            self.layers.add_module(\"dropout\", dropout_type(dropout_prob))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        new_features = self.layers(x)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "    \n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        layers: int,\n",
    "        in_channels: int,\n",
    "        bn_size: int,\n",
    "        growth_rate: int,\n",
    "        dropout_prob: float,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            layers: number of layers in the block.\n",
    "            in_channels: number of the input channel.\n",
    "            bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                (i.e. bn_size * k features in the bottleneck layer)\n",
    "            growth_rate: how many filters to add each layer (k in paper).\n",
    "            dropout_prob: dropout rate after each dense layer.\n",
    "            act: activation type and arguments. Defaults to relu.\n",
    "            norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        for i in range(layers):\n",
    "            layer = _DenseLayer(spatial_dims, in_channels, growth_rate, bn_size, dropout_prob, act=act, norm=norm)\n",
    "            in_channels += growth_rate\n",
    "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
    "            \n",
    "class DenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Densenet based on: `Densely Connected Convolutional Networks <https://arxiv.org/pdf/1608.06993.pdf>`_.\n",
    "    Adapted from PyTorch Hub 2D version: https://pytorch.org/vision/stable/models.html#id16.\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions of the input image.\n",
    "        in_channels: number of the input channel.\n",
    "        out_channels: number of the output classes.\n",
    "        init_features: number of filters in the first convolution layer.\n",
    "        growth_rate: how many filters to add each layer (k in paper).\n",
    "        block_config: how many layers in each pooling block.\n",
    "        bn_size: multiplicative factor for number of bottle neck layers.\n",
    "            (i.e. bn_size * k features in the bottleneck layer)\n",
    "        act: activation type and arguments. Defaults to relu.\n",
    "        norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        dropout_prob: dropout rate after each dense layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        init_features: int = 64,\n",
    "        growth_rate: int = 32,\n",
    "        block_config: Sequence[int] = (6, 12, 24, 16),\n",
    "        bn_size: int = 4,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "        dropout_prob: float = 0.0,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        conv_type: Type[Union[nn.Conv1d, nn.Conv2d, nn.Conv3d]] = Conv[Conv.CONV, spatial_dims]\n",
    "        pool_type: Type[Union[nn.MaxPool1d, nn.MaxPool2d, nn.MaxPool3d]] = Pool[Pool.MAX, spatial_dims]\n",
    "        avg_pool_type: Type[Union[nn.AdaptiveAvgPool1d, nn.AdaptiveAvgPool2d, nn.AdaptiveAvgPool3d]] = Pool[\n",
    "            Pool.ADAPTIVEAVG, spatial_dims\n",
    "        ]\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv0\", conv_type(in_channels, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                    (\"norm0\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=init_features)),\n",
    "                    (\"relu0\", get_act_layer(name=act)),\n",
    "                    (\"pool0\", pool_type(kernel_size=3, stride=2, padding=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_channels = init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                spatial_dims=spatial_dims,\n",
    "                layers=num_layers,\n",
    "                in_channels=in_channels,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                dropout_prob=dropout_prob,\n",
    "                act=act,\n",
    "                norm=norm,\n",
    "            )\n",
    "            self.features.add_module(f\"denseblock{i + 1}\", block)\n",
    "            in_channels += num_layers * growth_rate\n",
    "#             print('in_channels is ', in_channels)\n",
    "            if i == len(block_config) - 1:\n",
    "                self.features.add_module(\n",
    "                    \"norm5\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=in_channels)\n",
    "                )\n",
    "            else:\n",
    "                _out_channels = in_channels // 2\n",
    "                trans = _Transition(\n",
    "                    spatial_dims, in_channels=in_channels, out_channels=_out_channels, act=act, norm=norm\n",
    "                )\n",
    "                self.features.add_module(f\"transition{i + 1}\", trans)\n",
    "                in_channels = _out_channels\n",
    "\n",
    "        # pooling and classification\n",
    "        self.class_layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"relu\", get_act_layer(name=act)),\n",
    "                    (\"pool\", avg_pool_type(1)),\n",
    "                    (\"flatten\", nn.Flatten(1)),\n",
    "                    (\"out\", nn.Linear(in_channels, out_channels)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        ### get them out\n",
    "        self.class_layers_1 = get_act_layer(name=act)\n",
    "        self.class_layers_2 = avg_pool_type(1)\n",
    "        self.class_layers_3 = nn.Flatten(1)\n",
    "        MODAL = 1\n",
    "        self.class_layers_4 = nn.Linear(in_channels * MODAL, out_channels)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, conv_type):\n",
    "                nn.init.kaiming_normal_(torch.as_tensor(m.weight))\n",
    "            elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "                nn.init.constant_(torch.as_tensor(m.weight), 1)\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "\n",
    "        \n",
    "    def forward(self, x_T1_post: torch.Tensor\n",
    "                   ) -> torch.Tensor:   # [2, 1, 96, 96, 96]\n",
    "        ####  ==================== T1_pre ==================================\n",
    "        x_T1_post = self.features(x_T1_post)    # [2, 1024, 3, 3, 3]\n",
    "        x_T1_post = self.class_layers_1(x_T1_post)  # output: [2, 1024, 3, 3, 3]\n",
    "        x_T1_post = self.class_layers_2(x_T1_post) # output: [2, 1024, 1, 1, 1]\n",
    "        x_T1_post = self.class_layers_3(x_T1_post) # output: [2, 1024]\n",
    "        x_join = x_T1_post\n",
    "        linear_y = self.class_layers_4(x_join) # output: [2, 2]\n",
    "        out = self.sigmoid(linear_y)\n",
    "        return x_join, linear_y , out\n",
    "\n",
    "    \n",
    "class DenseNet121(DenseNet):\n",
    "    \"\"\"DenseNet121 with optional pretrained support when `spatial_dims` is 2.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_features: int = 32, # 64,\n",
    "        growth_rate: int = 16, # 32,\n",
    "        block_config: Sequence[int] = (3,6,12,8),#(6, 12, 24, 16),\n",
    "        pretrained: bool = False,\n",
    "        progress: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(init_features=init_features, growth_rate=growth_rate, block_config=block_config, **kwargs)\n",
    "        if pretrained:\n",
    "            if kwargs[\"spatial_dims\"] > 2:\n",
    "                raise NotImplementedError(\n",
    "                    \"Parameter `spatial_dims` is > 2 ; currently PyTorch Hub does not\"\n",
    "                    \"provide pretrained models for more than two spatial dimensions.\"\n",
    "                )\n",
    "            _load_state_dict(self, \"densenet121\", progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ImageDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate, Resize, ScaleIntensity, EnsureType\n",
    "\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((256,256,44)), RandRotate(range_x=0.02, range_y=0.02, range_z=0.02, prob=0.5), EnsureType()])\n",
    "val_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((256,256,44)), EnsureType()])\n",
    "\n",
    "#### ======================================= T1 post ===============================================\n",
    "# Define image dataset, data loader\n",
    "check_ds_T1_post = ImageDataset(image_files=images_T1_post_train, labels=labels_train, transform=train_transforms)\n",
    "check_loader_T1_post = DataLoader(check_ds_T1_post, batch_size=10, num_workers=2)# , pin_memory=torch.cuda.is_available())\n",
    "# create a training data loader\n",
    "train_ds_T1_post = ImageDataset(image_files=images_T1_post_train, labels=labels_train, transform=train_transforms)\n",
    "train_loader_T1_post = DataLoader(train_ds_T1_post, batch_size=10, shuffle=False, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "#create a validation data loader\n",
    "val_ds_T1_post = ImageDataset(image_files=images_T1_post_test, labels=labels_test, transform=val_transforms)\n",
    "val_loader_T1_post = DataLoader(val_ds_T1_post, batch_size=10, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "device = torch.device(14 if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss(weight=class_weights.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "\n",
    "triplet_loss = \\\n",
    "    nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance(), margin=1.5)\n",
    "\n",
    "\n",
    "\n",
    "# start a typical PyTorch training\n",
    "EPOCH = 400\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "best_AUC=0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{EPOCH}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    step = 0\n",
    "    total = 0\n",
    "    \n",
    "    iter_T1_post = iter(train_loader_T1_post)\n",
    "           \n",
    "    while step < len(train_loader_T1_post):\n",
    "        step += 1\n",
    "        inputs_T1_post, labels = next(iter_T1_post)\n",
    "        inputs_T1_post = inputs_T1_post.to(device)\n",
    "        one_hot_label = np.eye(2)[np.array(labels,dtype=\"int\")]\n",
    "        one_hot_label = torch.tensor(one_hot_label)\n",
    "        optimizer.zero_grad()\n",
    "        joint_embedding, out, predict = model(inputs_T1_post)\n",
    "        one_hot_label = one_hot_label.type_as(out).to(device)\n",
    "        loss_1 = loss_function(out, one_hot_label)\n",
    "\n",
    "        anchor = 0 \n",
    "        positive = [i for i, x in enumerate(labels) if x == 1]\n",
    "        negative = [i for i, x in enumerate(labels) if x == 0]\n",
    "        if not positive or not negative:\n",
    "            continue\n",
    "        loss = loss_1\n",
    "        for i in positive:\n",
    "            for j in negative:\n",
    "                loss += triplet_loss(0*joint_embedding[0,:], joint_embedding[i,:], joint_embedding[j,:])\n",
    "        loss.backward()\n",
    "        _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds_T1_post) // train_loader_T1_post.batch_size\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            num_correct = 0.0\n",
    "            metric_count = 0\n",
    "            pred_list = []\n",
    "            true_list = []\n",
    "            predicted_list=[]\n",
    "            prediction_probablity=[]\n",
    "            label_list = []\n",
    "            val_total=0\n",
    "            val_correct = 0\n",
    "            \n",
    "            iter_T1_post = iter(val_loader_T1_post)\n",
    "            step = 0\n",
    "            while step < len(val_loader_T1_post):\n",
    "                step += 1\n",
    "                val_images_T1_post, val_labels = next(iter_T1_post)\n",
    "                val_images_T1_post = val_images_T1_post.to(device)\n",
    "                _, out,predict = model(val_images_T1_post)\n",
    "                _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "                predicted_list.append(predicted.cpu().numpy())\n",
    "                predicted_2 = predict.detach().cpu().numpy()\n",
    "                prediction_prob = predicted_2[:,1].tolist()\n",
    "                prediction_probablity.extend(prediction_prob)\n",
    "                label_list.extend(val_labels.cpu().numpy().tolist())\n",
    "                val_total += val_labels.size(0)\n",
    "                val_correct += (predicted == val_labels).sum().item()\n",
    "            \n",
    "            \n",
    "            Accuracy = val_correct/val_total\n",
    "            y=np.array(label_list)\n",
    "            false_positive_rate, recall, thresholds = roc_curve(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "            roc_auc = auc(false_positive_rate, recall)\n",
    "            auprc = average_precision_score(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "            \n",
    "            if roc_auc > best_AUC:\n",
    "                best_AUC = roc_auc\n",
    "                torch.save(model.state_dict(), \"Models_saved-copy3-post-Medcam/State_checkpoints_{}.thr\".format(epoch))\n",
    "                torch.save(model, \"Models_saved-copy3-post-Medcam/Model_checkpoints_{}.thr\".format(epoch))\n",
    "            print(\"AUC: {} , Accuracy: {}, AUPRC: {}\".format(roc_auc, Accuracy, auprc))\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ======================================= T1 post ===============================================\n",
    "# Define image dataset, data loader\n",
    "check_ds_T1_post = ImageDataset(image_files=images_T1_post, labels=labels, transform=train_transforms)\n",
    "check_loader_T1_post = DataLoader(check_ds_T1_post, batch_size=1, num_workers=2)# , pin_memory=torch.cuda.is_available())\n",
    "im, label = monai.utils.misc.first(check_loader_T1_post)\n",
    "# create a training data loader\n",
    "train_ds_T1_post = ImageDataset(image_files=images_T1_post[:train_frac], labels=labels[:train_frac], transform=train_transforms)\n",
    "train_loader_T1_post = DataLoader(train_ds_T1_post, batch_size=1, shuffle=False, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "#create a validation data loader\n",
    "val_ds_T1_post = ImageDataset(image_files=images_T1_post[train_frac:], labels=labels[train_frac:], transform=val_transforms)\n",
    "val_loader_T1_post = DataLoader(val_ds_T1_post, batch_size=1, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Import M3d-CAM\n",
    "from medcam import medcam\n",
    "\n",
    "model.load_state_dict(torch.load(\"Models_saved-copy3-post-Medcam/State_checkpoints_{}.thr\".format()))\n",
    "# Inject model with M3d-CAM\n",
    "model_medCAM = medcam.inject(model, output_dir=\"T1-post_attention_maps\", save_maps=True)\n",
    "                 \n",
    "model_medCAM.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_correct = 0.0\n",
    "    metric_count = 0\n",
    "    pred_list = []\n",
    "    true_list = []\n",
    "    predicted_list=[]\n",
    "    prediction_probablity=[]\n",
    "    label_list = []\n",
    "    val_total=0\n",
    "    val_correct = 0\n",
    "\n",
    "    iter_T1_post = iter(val_loader_T1_post)\n",
    "    \n",
    "    step = 0\n",
    "    while step < len(val_loader_T1_post):\n",
    "        step += 1\n",
    "        val_images_T1_post, val_labels = next(iter_T1_post)\n",
    "        val_images_T1_post = val_images_T1_post.to(device)\n",
    "        _= model_medCAM(val_images_T1_post)\n",
    "        print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_images_T1_post.shape)\n",
    "import nibabel as nib\n",
    "test_mask=nib.load('T1-post_attention_maps/features.transition3.conv/attention_map_10_0_0.nii.gz')# .get_data()\n",
    "test_mask.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
