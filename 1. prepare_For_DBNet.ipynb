{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import evalml\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.utils import infer_feature_types\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score, roc_curve, auc, precision_recall_curve\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.va.gov/MS/Professionals/diagnosis/Kurtzke_Expanded_Disability_Status_Scale.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = '../ai_training_set'\n",
    "filelists = os.listdir(folder)\n",
    "\n",
    "for file in filelists:\n",
    "    if file not in ['Updated Database.xlsx', '.ipynb_checkpoints', 'AI_Notes']:\n",
    "        print(\"df_\" + file[:-4] + \"=pd.read_csv('\" + folder +\"/\" + file + \"')\")\n",
    "        exec(\"df_\" + file[:-4] + \"=pd.read_csv('\" + folder +\"/\" + file + \"')\")\n",
    "        print(\"display(\" + \"df_\" + file[:-4] + \".head(10))\")\n",
    "        exec(\"display(\" + \"df_\" + file[:-4] + \".head(10))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filelists:\n",
    "    print(\"df_\" + file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_AI_notes.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('df_AI_demographics')\n",
    "display(df_AI_demographics.head(3))\n",
    "print('df_AI_patient_facts')\n",
    "display(df_AI_patient_facts.head(3))\n",
    "print('df_AI_labs')\n",
    "display(df_AI_labs.head(3))\n",
    "print('df_AI_vitals')\n",
    "display(df_AI_vitals.head(3))\n",
    "print('df_AI_diagnoses')\n",
    "display(df_AI_diagnoses.head(3))\n",
    "print('df_AI_notes')\n",
    "display(df_AI_notes.head(3))\n",
    "print('df_AI_medications')\n",
    "display(df_AI_medications.head(3))\n",
    "print('df_AI_encounters')\n",
    "display(df_AI_encounters.head(3))\n",
    "print('df_AI_procedures')\n",
    "display(df_AI_procedures.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_AI_medications[df_AI_medications['M_MedDict']=='Topiramate 100 MG Oral Tablet']\n",
    "# df_AI_medications[df_AI_medications['M_MedDict']=='Topiramate 50 MG Oral Tablet']\n",
    "df_AI_medications['M_ndc'].nunique(),\\\n",
    "df_AI_medications['M_ItemID'].nunique(),\\\n",
    "df_AI_medications['M_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient EDSS scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edss_score_EDSS = pd.read_excel('../ai_training_set/Updated Database.xlsx', sheet_name='(5) EDSS')\n",
    "df_edss_score_MRI = pd.read_excel('../ai_training_set/Updated Database.xlsx', sheet_name='(6) MRI')\n",
    "\n",
    "df_edss_score_MRI = df_edss_score_MRI.dropna(subset=['record_id', 'allscripts_mrn'])\n",
    "\n",
    "## record_id --- allscripts_mrn\n",
    "record_id_TO_allscripts_mrn = {record_id: allscripts_mrn for record_id, allscripts_mrn in zip(df_edss_score_MRI['record_id'].to_list(), df_edss_score_MRI['allscripts_mrn'].to_list())}\n",
    "\n",
    "df_edss_score_EDSS = df_edss_score_EDSS.replace({\"record_id\": record_id_TO_allscripts_mrn}).rename(columns={'record_id': 'MRN'})\n",
    "\n",
    "df_edss_score_EDSS = df_edss_score_EDSS.dropna().reset_index(drop=True)\n",
    "\n",
    "result_EDSS = dict()  #{patient: {date: value}}\n",
    "for i in range(df_edss_score_EDSS.shape[0]):\n",
    "    mrn = df_edss_score_EDSS.loc[i, 'MRN']\n",
    "    date = df_edss_score_EDSS.loc[i, 'dov']\n",
    "    edss = df_edss_score_EDSS.loc[i, 'visit_edss']\n",
    "    if mrn not in result_EDSS:\n",
    "        result_EDSS[mrn] = dict()\n",
    "    if date not in result_EDSS[mrn]:\n",
    "        result_EDSS[mrn][date] = 0\n",
    "    result_EDSS[mrn][date] = edss\n",
    "    \n",
    "result_EDSS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Counter(df_AI_labs['IR_QO'])\n",
    "# print(a.most_common(80))\n",
    "labs_selected = [x[0] for x in a.most_common()[:80]]\n",
    "\n",
    "\n",
    "a = Counter(df_AI_vitals['IF_QO'])\n",
    "# print(a.most_common(20))\n",
    "vitals_selected = [x[0] for x in a.most_common()[:12]]\n",
    "\n",
    "a = Counter(df_AI_medications['M_MedDict'])\n",
    "# print(a.most_common(30))\n",
    "meds_selected = [x[0] for x in a.most_common()[:12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lab preprocess\n",
    "df_AI_labs['R_ResultDTTM'] = pd.to_datetime(df_AI_labs['R_ResultDTTM'])\n",
    "df_AI_labs = df_AI_labs[df_AI_labs['IR_QO'].isin(labs_selected)]\n",
    "lab_names_mapping = {name: i for i, name in enumerate(labs_selected)}\n",
    "### vital preprocess\n",
    "PatientID_TO_MRN = {PatientID: MRN for PatientID, MRN in zip(df_AI_labs['PatientID'].to_list(), \n",
    "                                                             df_AI_labs['MRN'].to_list())}\n",
    "df_AI_vitals = df_AI_vitals.replace({\"PatientID\": PatientID_TO_MRN}).rename(columns={'PatientID': 'MRN'})\n",
    "df_AI_vitals['F_ClinicalDTTM'] = pd.to_datetime(df_AI_vitals['F_ClinicalDTTM'])\n",
    "df_AI_vitals = df_AI_vitals[df_AI_vitals['IF_QO'].isin(vitals_selected)]\n",
    "vital_names_mapping = {name: i for i, name in enumerate(vitals_selected)}\n",
    "### med preprocess\n",
    "PatientID_TO_MRN = {PatientID: MRN for PatientID, MRN in zip(df_AI_labs['PatientID'].to_list(), \n",
    "                                                             df_AI_labs['MRN'].to_list())}\n",
    "df_AI_medications = df_AI_medications.replace({\"PatientID\": PatientID_TO_MRN}).rename(columns={'PatientID': 'MRN'})\n",
    "df_AI_medications['IM_PerformedDTTM'] = pd.to_datetime(df_AI_medications['IM_PerformedDTTM'])\n",
    "df_AI_medications = df_AI_medications[df_AI_medications['M_MedDict'].isin(meds_selected)]\n",
    "med_names_mapping = {name: i for i, name in enumerate(meds_selected)}\n",
    "### df_AI_demographics \n",
    "df_AI_demographics_2 = df_AI_demographics[['MRN', 'Race','Sex']]\n",
    "df_AI_demographics_2 = pd.get_dummies(df_AI_demographics_2 , columns=['Race','Sex'])\n",
    "### df_AI_patient_facts \n",
    "df_AI_patient_facts_2  = df_AI_patient_facts[['MRN', 'Race', 'Ethnicity']]\n",
    "df_AI_patient_facts_2  = pd.get_dummies(df_AI_patient_facts_2, columns=['Race', 'Ethnicity'])\n",
    "\n",
    "# MRI -> MRN\n",
    "master_sheet = pd.read_excel('../ai_training_set/Updated Database.xlsx', sheet_name = '(6) MRI')\n",
    "dict_MRI_MRN = {str(int(a)):str(int(b)) for a,b in  zip(master_sheet['ut_scan_id'].to_list(), \n",
    "                                                        master_sheet['allscripts_mrn'].to_list()) if not pd.isna(a) and not pd.isna(b)}\n",
    "\n",
    "# MRI_Train is the MRI Image train set of MRIs\n",
    "import pickle\n",
    "with open('embeddings_T2/MRIs_train.pkl', 'rb') as f:\n",
    "    train_MRIs = pickle.load(f)\n",
    "with open('embeddings_T2/MRIs_test.pkl', 'rb') as f:\n",
    "    test_MRIs = pickle.load(f)\n",
    "T2_embedding_list_test = np.load('embeddings_T2/xgboost_embedding_list_test.npy')\n",
    "T2_embedding_list_train = np.load('embeddings_T2/xgboost_embedding_list_train.npy')\n",
    "T2_label_list_test = np.load('embeddings_T2/xgboost_label_list_test.npy')\n",
    "T2_label_list_train = np.load('embeddings_T2/xgboost_label_list_train.npy')\n",
    "\n",
    "T1_pre_embedding_list_test = np.load('embeddings_T1_pre/xgboost_embedding_list_test.npy')\n",
    "T1_pre_embedding_list_train = np.load('embeddings_T1_pre/xgboost_embedding_list_train.npy')\n",
    "T1_pre_label_list_test = np.load('embeddings_T1_pre/xgboost_label_list_test.npy')\n",
    "T1_pre_label_list_train = np.load('embeddings_T1_pre/xgboost_label_list_train.npy')\n",
    "\n",
    "T1_post_embedding_list_test = np.load('embeddings_T1_post/xgboost_embedding_list_test.npy')\n",
    "T1_post_embedding_list_train = np.load('embeddings_T1_post/xgboost_embedding_list_train.npy')\n",
    "T1_post_label_list_test = np.load('embeddings_T1_post/xgboost_label_list_test.npy')\n",
    "T1_post_label_list_train = np.load('embeddings_T1_post/xgboost_label_list_train.npy')\n",
    "\n",
    "flair_embedding_list_test = np.load('embeddings_flair/xgboost_embedding_list_test.npy')\n",
    "flair_embedding_list_train = np.load('embeddings_flair/xgboost_embedding_list_train.npy')\n",
    "flair_label_list_test = np.load('embeddings_flair/xgboost_label_list_test.npy')\n",
    "flair_label_list_train = np.load('embeddings_flair/xgboost_label_list_train.npy')\n",
    "\n",
    "pd_embedding_list_test = np.load('embeddings_pd/xgboost_embedding_list_test.npy')\n",
    "pd_embedding_list_train = np.load('embeddings_pd/xgboost_embedding_list_train.npy')\n",
    "pd_label_list_test = np.load('embeddings_pd/xgboost_label_list_test.npy')\n",
    "pd_label_list_train = np.load('embeddings_pd/xgboost_label_list_train.npy')\n",
    "\n",
    "\n",
    "assert np.array_equal(T2_label_list_train, T1_pre_label_list_train)\n",
    "assert np.array_equal(T2_label_list_test , T1_pre_label_list_test )\n",
    "assert np.array_equal( T2_label_list_train , T1_post_label_list_train) \n",
    "assert np.array_equal( T2_label_list_test , T1_post_label_list_test)\n",
    "assert np.array_equal( T2_label_list_train , flair_label_list_train )\n",
    "assert np.array_equal(  T2_label_list_test , flair_label_list_test)\n",
    "assert np.array_equal( T2_label_list_train, pd_label_list_train )\n",
    "assert np.array_equal(  T2_label_list_test , pd_label_list_test)\n",
    "\n",
    "\n",
    "# Make MRN_train, which corresponds to MRI_Train\n",
    "train_MRNs = [dict_MRI_MRN[i] for i in train_MRIs]\n",
    "test_MRNs = [dict_MRI_MRN[i] for i in test_MRIs]\n",
    "\n",
    "# make it a dictionary\n",
    "d_mrn_embedding_train_T1_pre = {a:b for a,b in zip(train_MRNs, T1_pre_embedding_list_train)}\n",
    "d_mrn_embedding_test_T1_pre = {a:b for a,b in zip(test_MRNs, T1_pre_embedding_list_test)}\n",
    "d_mrn_embedding_train_T1_post = {a:b for a,b in zip(train_MRNs, T1_post_embedding_list_train)}\n",
    "d_mrn_embedding_test_T1_post = {a:b for a,b in zip(test_MRNs, T1_post_embedding_list_test)}\n",
    "d_mrn_embedding_train_T2 = {a:b for a,b in zip(train_MRNs, T2_embedding_list_train)}\n",
    "d_mrn_embedding_test_T2 = {a:b for a,b in zip(test_MRNs, T2_embedding_list_test)}\n",
    "d_mrn_embedding_train_flair= {a:b for a,b in zip(train_MRNs, flair_embedding_list_train)}\n",
    "d_mrn_embedding_test_flair = {a:b for a,b in zip(test_MRNs, flair_embedding_list_test)}\n",
    "d_mrn_embedding_train_pd = {a:b for a,b in zip(train_MRNs, pd_embedding_list_train)}\n",
    "d_mrn_embedding_test_pd = {a:b for a,b in zip(test_MRNs, pd_embedding_list_test)}\n",
    "\n",
    "## note embeddings\n",
    "with open(\"../../Github_DocumentClassification-MPAD(my-code-Here)/mpad-master/mpad/result_MPAD_embedding.pickle\", 'rb') as f:\n",
    "    note_embeddings = pickle.load(f)\n",
    "note_embeddings = {a:b for a,b in note_embeddings}\n",
    "\n",
    "\n",
    "MS_train = []\n",
    "MS_test = []\n",
    "\n",
    "for mrn, time_value in tqdm(result_EDSS.items()):\n",
    "    label = 0\n",
    "    for time, value in time_value.items():\n",
    "        time_reach_4 = time\n",
    "        if value > 4.0: \n",
    "            label = 1\n",
    "            break\n",
    "        \n",
    "    ###  ==================== lab ===========================\n",
    "    n_col = len(lab_names_mapping)\n",
    "    lab_i = [[0] * n_col]\n",
    "\n",
    "    patient_lab = df_AI_labs[(df_AI_labs['MRN'] == mrn) & \n",
    "                             ((df_AI_labs['R_ResultDTTM'] < time_reach_4))].sort_values(by='R_ResultDTTM').reset_index(drop=True)\n",
    "\n",
    "    if patient_lab.shape[0] != 0:\n",
    "        prev_date = patient_lab.loc[0, 'R_ResultDTTM']\n",
    "\n",
    "        for j in range(patient_lab.shape[0]):\n",
    "            col = lab_names_mapping[patient_lab.loc[j, 'IR_QO']]\n",
    "            val = patient_lab.loc[j, 'IR_DecodedValue']\n",
    "            cur_date = patient_lab.loc[j, 'R_ResultDTTM']\n",
    "            try: \n",
    "                val = float(val)\n",
    "            except:\n",
    "                continue\n",
    "            if np.isnan(val):\n",
    "                continue\n",
    "\n",
    "            if cur_date != prev_date:\n",
    "                lab_i.append([0] * n_col)\n",
    "                prev_date = cur_date\n",
    "            lab_i[-1][col] =val\n",
    "\n",
    "\n",
    "    ###  ==================== vital===========================\n",
    "    n_col = len(vital_names_mapping)\n",
    "    vital_i = [[0] * n_col]\n",
    "\n",
    "    patient_vital = df_AI_vitals[(df_AI_vitals['MRN'] == mrn) & ((df_AI_vitals['F_ClinicalDTTM'] < time_reach_4))].sort_values(by='F_ClinicalDTTM').reset_index(drop=True)\n",
    "\n",
    "    if patient_vital.shape[0] != 0:\n",
    "        prev_date = patient_vital.loc[0, 'F_ClinicalDTTM']\n",
    "\n",
    "        for j in range(patient_vital.shape[0]):\n",
    "            col = vital_names_mapping[patient_vital.loc[j, 'IF_QO']]\n",
    "            val = patient_vital.loc[j, 'F_NormalizedValue']\n",
    "            cur_date = patient_vital.loc[j, 'F_ClinicalDTTM']\n",
    "            try: \n",
    "                val = float(val)\n",
    "            except:\n",
    "                continue\n",
    "            if np.isnan(val):\n",
    "                continue\n",
    "\n",
    "            if cur_date != prev_date:\n",
    "                vital_i.append([0] * n_col)\n",
    "                prev_date = cur_date\n",
    "            vital_i[-1][col] =val\n",
    "\n",
    "    \n",
    "    ###  ==================== medications ==========================\n",
    "    n_col = len(med_names_mapping)\n",
    "    med_i = [[0] * n_col]\n",
    "\n",
    "    patient_med = df_AI_medications[(df_AI_medications['MRN'] == mrn) & ((df_AI_medications['IM_PerformedDTTM'] < time_reach_4))].sort_values(by='IM_PerformedDTTM').reset_index(drop=True)\n",
    "\n",
    "    if patient_med.shape[0] != 0:\n",
    "        prev_date = patient_med.loc[0, 'IM_PerformedDTTM']\n",
    "\n",
    "        for j in range(patient_med.shape[0]):\n",
    "            col = med_names_mapping[patient_med.loc[j, 'M_MedDict']]\n",
    "            val = 1\n",
    "            cur_date = patient_med.loc[j, 'IM_PerformedDTTM']\n",
    "            try: \n",
    "                val = float(val)\n",
    "            except:\n",
    "                continue\n",
    "            if np.isnan(val):\n",
    "                continue\n",
    "\n",
    "            if cur_date != prev_date:\n",
    "                med_i.append([0] * n_col)\n",
    "                prev_date = cur_date\n",
    "            med_i[-1][col] =val\n",
    "\n",
    "    \n",
    "    ###  ==================== demographics ==========================\n",
    "    demo_i_1 = df_AI_demographics_2[df_AI_demographics['MRN']==mrn].drop(columns='MRN').values.tolist()\n",
    "    if not demo_i_1:\n",
    "        demo_i_1 = [0] * len(list(df_AI_demographics_2.columns.drop('MRN')))\n",
    "    else:\n",
    "        demo_i_1 = demo_i_1[0]\n",
    "    demo_i_2 = df_AI_patient_facts_2[df_AI_patient_facts['MRN']==mrn].drop(columns='MRN').values.tolist()\n",
    "    if not demo_i_2:\n",
    "        demo_i_2 = [0] * len(list(df_AI_patient_facts_2.columns.drop('MRN')))\n",
    "    else:\n",
    "        demo_i_2 = demo_i_2[0]\n",
    "    demo_i = demo_i_1 +  demo_i_2\n",
    "    \n",
    "    \n",
    "    ### ========================== Note Embeddings ====================================\n",
    "    note_i = note_embeddings[mrn]\n",
    "\n",
    "    ### ======================= EDSS score ===========================\n",
    "    label_i = label\n",
    "\n",
    "\n",
    "    ### ==================== MRI Embeddings ==========================\n",
    "    ### ===== if MRN has image data and in train =====\n",
    "    if str(int(mrn)) in d_mrn_embedding_train:\n",
    "        mri_embed_T1_pre_i = d_mrn_embedding_train_T1_pre[str(int(mrn))]\n",
    "        mri_embed_T1_post_i = d_mrn_embedding_train_T1_post[str(int(mrn))]\n",
    "        mri_embed_T2_i = d_mrn_embedding_train_T2[str(int(mrn))]\n",
    "        mri_embed_flair_i = d_mrn_embedding_train_flair[str(int(mrn))]\n",
    "        mri_embed_pd_i = d_mrn_embedding_train_pd[str(int(mrn))]\n",
    "        MS_train.append((str(int(mrn)), (torch.tensor(lab_i, dtype = torch.float32), \n",
    "                                         torch.tensor(vital_i, dtype = torch.float32), \n",
    "                                         torch.tensor(med_i, dtype = torch.float32), \n",
    "                                         torch.tensor(note_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_pre_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_post_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T2_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_flair_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_pd_i, dtype = torch.float32), \n",
    "                                         torch.tensor(demo_i, dtype = torch.float32), \n",
    "                                         label_i)))\n",
    "    ### ====== if MRN has image data and in test =======\n",
    "    elif str(int(mrn)) in d_mrn_embedding_test:\n",
    "        mri_embed_T1_pre_i = d_mrn_embedding_test_T1_pre[str(int(mrn))]\n",
    "        mri_embed_T1_post_i = d_mrn_embedding_test_T1_post[str(int(mrn))]\n",
    "        mri_embed_T2_i = d_mrn_embedding_test_T2[str(int(mrn))]\n",
    "        mri_embed_flair_i = d_mrn_embedding_test_flair[str(int(mrn))]\n",
    "        mri_embed_pd_i = d_mrn_embedding_test_pd[str(int(mrn))]\n",
    "        MS_test.append((str(int(mrn)), (torch.tensor(lab_i, dtype = torch.float32), \n",
    "                                         torch.tensor(vital_i, dtype = torch.float32), \n",
    "                                         torch.tensor(med_i, dtype = torch.float32), \n",
    "                                         torch.tensor(note_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_pre_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_post_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T2_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_flair_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_pd_i, dtype = torch.float32), \n",
    "                                         torch.tensor(demo_i, dtype = torch.float32), \n",
    "                                         label_i)))\n",
    "    ### ========= if MRN don't have image, create empty image embedding and put this patient randomly to train/test\n",
    "    else:\n",
    "        mri_embed_T1_pre_i = np.zeros(shape=(258,))\n",
    "        mri_embed_T1_post_i = np.zeros(shape=(258,))\n",
    "        mri_embed_T2_i = np.zeros(shape=(258,))\n",
    "        mri_embed_flair_i = np.zeros(shape=(258,))\n",
    "        mri_embed_pd_i = np.zeros(shape=(258,))\n",
    "        if np.random.random() < 0.5:\n",
    "            MS_train.append((str(int(mrn)), (torch.tensor(lab_i, dtype = torch.float32), \n",
    "                                         torch.tensor(vital_i, dtype = torch.float32), \n",
    "                                         torch.tensor(med_i, dtype = torch.float32), \n",
    "                                         torch.tensor(note_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_pre_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_post_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T2_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_flair_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_pd_i, dtype = torch.float32), \n",
    "                                         torch.tensor(demo_i, dtype = torch.float32), \n",
    "                                         label_i)))\n",
    "        else:\n",
    "            MS_test.append((str(int(mrn)), (torch.tensor(lab_i, dtype = torch.float32), \n",
    "                                         torch.tensor(vital_i, dtype = torch.float32), \n",
    "                                         torch.tensor(med_i, dtype = torch.float32), \n",
    "                                         torch.tensor(note_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_pre_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T1_post_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_T2_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_flair_i, dtype = torch.float32), \n",
    "                                         torch.tensor(mri_embed_pd_i, dtype = torch.float32), \n",
    "                                         torch.tensor(demo_i, dtype = torch.float32), \n",
    "                                         label_i)))\n",
    "            \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AI_demographics_2[df_AI_demographics['MRN']==mrn].drop(columns='MRN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MRI——》MRN是多对1的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train_MRIs)),\\\n",
    "len(set(test_MRIs)),\\\n",
    "len(set(train_MRIs).intersection(set(test_MRIs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train_MRNs)),\\\n",
    "len(set(test_MRNs)),\\\n",
    "len(set(train_MRNs).intersection(set(test_MRNs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0\n",
    "n = 0\n",
    "na = 0\n",
    "for mrn, time_value in tqdm(result_EDSS.items()):\n",
    "    if str(int(mrn)) in d_mrn_embedding_train:\n",
    "#          print('+')\n",
    "         p+= 1\n",
    "    elif str(int(mrn)) in d_mrn_embedding_test:\n",
    "#          print('-')\n",
    "         n+=1\n",
    "    else:\n",
    "#         print('no')\n",
    "        na+=1\n",
    "print(p, n, na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d_mrn_embedding_train.keys()), \\\n",
    "len(d_mrn_embedding_test.keys()), \\\n",
    "len(set(d_mrn_embedding_train.keys()).intersection(set(d_mrn_embedding_test.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mrn_embedding_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mrn_embedding_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MS_train), len(MS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MS_train.pt', 'wb') as f:\n",
    "    pickle.dump(MS_train, f)\n",
    "with open('MS_test.pt', 'wb') as f:\n",
    "    pickle.dump(MS_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('MS_train.pt', 'rb') as f:\n",
    "    MS_train = pickle.load(f)\n",
    "with open('MS_test.pt', 'rb') as f:\n",
    "    MS_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(MS_train[0][1][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result_EDSS))\n",
    "print(len(d_mrn_embedding_train), len(d_mrn_embedding_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mrn_embedding_train.keys(), d_mrn_embedding_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_MRIs)), print(len(test_MRIs))\n",
    "print(len(train_MRNs)), print(len(test_MRNs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_selected[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in labs_selected:\n",
    "#     print(\"'\"+i.split(' ')[0]+\"',\")\n",
    "    tmp.append(i)\n",
    "print(tmp)\n",
    "\n",
    "tmp = []\n",
    "for i in vitals_selected:\n",
    "#     print(\"'\"+i.split(' ')[0]+\"',\")\n",
    "    tmp.append(i)\n",
    "print(tmp)\n",
    "\n",
    "tmp = []\n",
    "for i in meds_selected:\n",
    "#     print(\"'\"+i.split(' ')[0]+\"',\")\n",
    "    tmp.append(i)\n",
    "print(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
