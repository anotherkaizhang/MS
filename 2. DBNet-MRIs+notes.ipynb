{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 5,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(x, y, figname):\n",
    "    if len(y) == 0: return\n",
    "    \n",
    "#     p0 = len(x)\n",
    "#     for i in range(y.shape[0]):\n",
    "#         if y[i] == y[i+1] and y[i+1] == y[i+2]:\n",
    "#             p0 = i+2\n",
    "#             break\n",
    "\n",
    "#     x = x[:p0]\n",
    "#     y = y[:p0]\n",
    "#     print(x.shape, y.shape)\n",
    "    fig, (ax,ax2) = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "    extent = [x[0]-(x[1]-x[0])/2., x[-1]+(x[1]-x[0])/2.,0,1]\n",
    "    ax.imshow(y[np.newaxis,:], cmap=\"plasma\", aspect=\"auto\", extent=extent)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(extent[0], extent[1])\n",
    "    ax.set_xlabel(\"Time (by 4 hours)\")\n",
    "#     ax2.set_xlabel(\"Feature (index)\")\n",
    "    ax.set_ylabel(\"Weight\")\n",
    "    \n",
    "    ax2.plot(x,y)\n",
    "    ax2.set_xlabel(\"Time (by 4 hours)\")\n",
    "#     ax2.set_xlabel(\"Feature (index)\")\n",
    "    ax2.set_ylabel(\"Weight\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_featuremap(x, y, figname):\n",
    "    if len(y) == 0: return\n",
    "    \n",
    "#     p0 = len(x)\n",
    "#     for i in range(y.shape[0]):\n",
    "#         if y[i] == y[i+1] and y[i+1] == y[i+2]:\n",
    "#             p0 = i+2\n",
    "#             break\n",
    "\n",
    "#     x = x[:p0]\n",
    "#     y = y[:p0]\n",
    "#     print(x.shape, y.shape)\n",
    "    fig, (ax,ax2) = plt.subplots(nrows=2, sharex=True)\n",
    "\n",
    "    extent = [x[0]-(x[1]-x[0])/2., x[-1]+(x[1]-x[0])/2.,0,1]\n",
    "    ax.imshow(y[np.newaxis,:], cmap=\"plasma\", aspect=\"auto\", extent=extent)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(extent[0], extent[1])\n",
    "#     ax.set_xlabel(\"Time (by 4 hours)\")\n",
    "    ax2.set_xlabel(\"Feature (index)\")\n",
    "    ax.set_ylabel(\"Weight\")\n",
    "    \n",
    "    ax2.plot(x,y)\n",
    "#     ax2.set_xlabel(\"Time (by 4 hours)\")\n",
    "    ax2.set_xlabel(\"Feature (index)\")\n",
    "    ax2.set_ylabel(\"Weight\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figname)\n",
    "    plt.show()\n",
    "    \n",
    "    # print top 10 features\n",
    "    top10=np.argsort(y)[-10:][::-1]\n",
    "    \n",
    "    print('top10 features are', top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('MS_train.pt', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('MS_test.pt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data[0]) ,len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0][1][0].shape, test_data[0][1][1].shape, test_data[0][1][2].shape, test_data[0][1][3].shape, test_data[0][1][4].shape, \\\n",
    "test_data[0][1][5].shape, test_data[0][1][6].shape, test_data[0][1][7].shape, test_data[0][1][8].shape, test_data[0][1][9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class Covid_19(Dataset):\n",
    "    def __init__(self,dataList):\n",
    "        self.data_list = dataList\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(\"idx\",idx)\n",
    "        ptid = self.data_list[idx][0]\n",
    "        sample = self.data_list[idx][1]\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class Sampler(torch.utils.data.sampler.Sampler):\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "        self.callback_get_label = callback_get_label\n",
    "\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        return dataset[idx][-1]\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (pt_lab_batch, pt_vital_batch, pt_med_batch, \n",
    "     notes_embed_i, \n",
    "     T1_pre_embed_i, T1_post_embed_i, T2_embed_i, flair_embed_i, pd_embed_i,\n",
    "     pt_demo_batch, \n",
    "     label_batch) = zip(*batch)\n",
    "    \n",
    "    pt_notes_embed_batch =torch.stack([item[3] for item in batch])\n",
    "    pt_T1_pre_embed_batch =torch.stack([item[4] for item in batch])\n",
    "    pt_T1_post_embed_batch =torch.stack([item[5] for item in batch])\n",
    "    pt_T2_embed_batch =torch.stack([item[6] for item in batch])\n",
    "    pt_flair_embed_batch =torch.stack([item[7] for item in batch])\n",
    "    pt_pd_embed_batch =torch.stack([item[8] for item in batch])\n",
    "    pt_demo_batch =torch.stack([item[9] for item in batch])\n",
    "    label_batch =[item[10] for item in batch]\n",
    "\n",
    "    max_lab = np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_lab_batch]),axis=0)\n",
    "    max_vital = np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_vital_batch]),axis=0)\n",
    "    max_med= np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_med_batch]),axis=0)\n",
    "\n",
    "    lab_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_lab[1] - DB.size(1), 0, max_lab[0] - DB.size(0)])\n",
    "        for DB in pt_lab_batch\n",
    "        ])\n",
    "    vital_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_vital[1] - DB.size(1), 0, max_vital[0] - DB.size(0)])\n",
    "        for DB in pt_vital_batch\n",
    "        ])\n",
    "    med_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_med[1] - DB.size(1), 0, max_med[0] - DB.size(0)])\n",
    "        for DB in pt_med_batch\n",
    "        ])\n",
    "\n",
    "\n",
    "    return lab_batch, vital_batch, med_batch, pt_notes_embed_batch, \\\n",
    "            pt_T1_pre_embed_batch, pt_T1_post_embed_batch, pt_T2_embed_batch, pt_flair_embed_batch, pt_pd_embed_batch, \\\n",
    "            pt_demo_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class Sampler(torch.utils.data.sampler.Sampler):\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "        self.callback_get_label = callback_get_label\n",
    "\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        return dataset[idx][-1]\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset=Covid_19(train_data)\n",
    "validation_dataset = Covid_19(test_data)\n",
    "trainSampler = Sampler(train_dataset)\n",
    "dataloader = DataLoader(train_dataset, batch_size=24,\n",
    "                        shuffle=False, num_workers=0,drop_last=True,collate_fn=pad_collate,sampler = trainSampler)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=24,\n",
    "                        shuffle=False, num_workers=0,drop_last=True,collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBNet(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DBNet, self).__init__()\n",
    "        \n",
    "        ####vars to set\n",
    "        dropout_GRU = 0.5\n",
    "        hidden_size=512\n",
    "        no_GRU_layers=4\n",
    "        output_size = 2\n",
    "        GRU_input_size = 258 \n",
    "        no_hops = 8\n",
    "        \n",
    "        \n",
    "        ###(kernel_size,in_channel,out_channel, stride,pad)  \n",
    "        lab_kernels = [(7,1,8,2,0),(4,8,8,2,0),(3,8,1,2,1)]\n",
    "        vital_kernels =  [(3,1,8,2,0),(2,8,1,2,1)]\n",
    "        medAdmin_kernels = [(3,1,8,2,0),(2,8,1,2,1)]\n",
    "\n",
    "        self.lab_layers = nn.ModuleList()\n",
    "        self.vital_layers = nn.ModuleList()\n",
    "        self.medAdmin_layers = nn.ModuleList()\n",
    "\n",
    "        self.make_encoder_block(lab_kernels,self.lab_layers)\n",
    "        self.make_encoder_block(vital_kernels,self.vital_layers)\n",
    "        self.make_encoder_block(medAdmin_kernels,self.medAdmin_layers)\n",
    "\n",
    "        self.GRU = nn.GRU(GRU_input_size, hidden_size, no_GRU_layers, dropout=dropout_GRU,\n",
    "                                         batch_first=True, bias=False, bidirectional=True)\n",
    "        self.GRU_dropout = nn.Dropout(p=dropout_GRU)\n",
    "        self.conv_att = nn.Conv1d(in_channels=1, out_channels=no_hops, kernel_size=hidden_size * 2, stride=1)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size * 2 * no_hops + 21, output_size, bias=False)\n",
    "\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Hardtanh(0, 1)\n",
    "        self.init_weights()\n",
    "        self.no_hops = no_hops\n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_size = output_size\n",
    "        self.no_GRU_layers = no_GRU_layers\n",
    "\n",
    "        \n",
    "    def make_encoder_block(self,kernel_list,layer_list):\n",
    "        for i,kernels in enumerate(kernel_list):\n",
    "            layer_list.append(nn.Conv1d(in_channels=kernels[1],\n",
    "                                        out_channels=kernels[2],\n",
    "                                        kernel_size=kernels[0],\n",
    "                                        stride=kernels[3],\n",
    "                                        padding=kernels[4]))\n",
    "            if i <len(layer_list)-1:\n",
    "                layer_list.append(nn.ReLU())\n",
    "            layer_list.append(nn.Dropout(p=0.3))\n",
    "        layer_list.append(nn.AdaptiveAvgPool1d(1))\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "    def lab_encoder(self, lab):\n",
    "        encoded_DAMs=[]\n",
    "        for i in range(lab.size(1)):\n",
    "            for j,layer in enumerate(self.lab_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(lab[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_DAMs.append(out)\n",
    "        # ------------ plot attention weights\n",
    "#         print('Attension weights is encoded_DAMs is', len(encoded_DAMs))\n",
    "#         x = np.array(range(len(encoded_DAMs)), dtype=int)\n",
    "#         y = np.array([[i[0][0][0].item() for i in encoded_DAMs]]).squeeze()\n",
    "#         plot_attention(x, y, 'time-lab.pdf')\n",
    "        # -----------------------------------\n",
    "        encoded_DAMs = torch.stack(encoded_DAMs)\n",
    "        encoded_DAMs = torch.squeeze(encoded_DAMs, dim=3)\n",
    "        encoded_DAMs = torch.transpose(encoded_DAMs, 0, 1)\n",
    "        encoded_DAMs = torch.transpose(encoded_DAMs, 1, 2)\n",
    "        encoded_DAMs = self.tanh(encoded_DAMs)\n",
    "        encoded_DAMs = torch.bmm(encoded_DAMs, lab)\n",
    "        encoded_DAMs = torch.squeeze(encoded_DAMs, dim=1)\n",
    "        # ------------ plot feature weights\n",
    "#         print('Feature weights is encoded_DAMs is', len(encoded_DAMs), encoded_DAMs.shape)\n",
    "#         x = np.array(range(encoded_DAMs.shape[1]), dtype=int)\n",
    "#         y = encoded_DAMs[0,:].cpu().detach().numpy()\n",
    "#         plot_featuremap(x, y, 'feature_lab.pdf')\n",
    "        # -----------------------------------\n",
    "        return encoded_DAMs\n",
    "    \n",
    "    def vital_encoder(self, vital):\n",
    "        encoded_DPCs=[]\n",
    "        for i in range(vital.size(1)):\n",
    "            for j,layer in enumerate(self.vital_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(vital[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_DPCs.append(out)\n",
    "        # ------------ plot attention weights\n",
    "#         print('Attension weights is encoded_DPCs is', len(encoded_DPCs))\n",
    "#         x = np.array(range(len(encoded_DPCs)), dtype=int)\n",
    "#         y = np.array([[i[0][0][0].item() for i in encoded_DPCs]]).squeeze()\n",
    "#         plot_attention(x, y, 'time-diag.pdf')\n",
    "        # -----------------------------------    \n",
    "        encoded_DPCs = torch.stack(encoded_DPCs)\n",
    "        encoded_DPCs = torch.squeeze(encoded_DPCs, dim=3)\n",
    "        encoded_DPCs =  torch.transpose(encoded_DPCs, 0, 1)\n",
    "        encoded_DPCs = torch.transpose(encoded_DPCs, 1, 2)\n",
    "        encoded_DPCs = self.tanh(encoded_DPCs)\n",
    "        encoded_DPCs = torch.bmm(encoded_DPCs, vital)\n",
    "        encoded_DPCs = torch.squeeze(encoded_DPCs, dim=1)\n",
    "        # ------------ plot feature weights\n",
    "#         print('Feature weights is encoded_DPCs is', len(encoded_DPCs), encoded_DPCs.shape)\n",
    "#         x = np.array(range(encoded_DPCs.shape[1]), dtype=int)\n",
    "#         y = encoded_DPCs[0,:].cpu().detach().numpy()\n",
    "#         plot_featuremap(x, y, 'feature-diag.pdf')\n",
    "        # -----------------------------------\n",
    "        return encoded_DPCs\n",
    "    \n",
    "    def medAdmin_encoder(self, medAdmin):\n",
    "        encoded_medAdmins = []\n",
    "        for i in range(medAdmin.size(1)):\n",
    "            for j,layer in enumerate(self.medAdmin_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(medAdmin[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_medAdmins.append(out)\n",
    "        # ------------ plot attention weights\n",
    "#         print('Attension weights is encoded_medAdmins is', len(encoded_medAdmins))\n",
    "#         x = np.array(range(len(encoded_medAdmins)), dtype=int)\n",
    "#         y = np.array([[i[0][0][0].item() for i in encoded_medAdmins]]).squeeze()\n",
    "#         plot_attention(x, y,'time-medAdmin.pdf')\n",
    "        # ----------------------------------- \n",
    "        encoded_medAdmins = torch.stack(encoded_medAdmins)\n",
    "        encoded_medAdmins = torch.squeeze(encoded_medAdmins, dim=3)\n",
    "        encoded_medAdmins =  torch.transpose(encoded_medAdmins, 0, 1)\n",
    "        encoded_medAdmins = torch.transpose(encoded_medAdmins, 1, 2)\n",
    "        encoded_medAdmins = self.tanh(encoded_medAdmins)\n",
    "        encoded_medAdmins = torch.bmm(encoded_medAdmins, medAdmin)\n",
    "        encoded_medAdmins = torch.squeeze(encoded_medAdmins, dim=1)\n",
    "        # ------------ plot feature weights\n",
    "#         print('Feature weights is encoded_medAdmins is', len(encoded_medAdmins), encoded_medAdmins.shape)\n",
    "#         x = np.array(range(encoded_medAdmins.shape[1]), dtype=int)\n",
    "#         y = encoded_medAdmins[0,:].cpu().detach().numpy()\n",
    "#         plot_featuremap(x, y, 'feature-medAdmins.pdf')\n",
    "        # -----------------------------------\n",
    "        return encoded_medAdmins\n",
    "    \n",
    "    \n",
    "    def init_GRU(self, batch_size):\n",
    "        self.weight = next(self.parameters()).data\n",
    "        init_state = (Variable(self.weight.new(self.no_GRU_layers * 2, batch_size, self.hidden_size).zero_()))\n",
    "        return init_state\n",
    "\n",
    "    \n",
    "    def GRU_Decoder(self, inputs,batch_size):\n",
    "        inputs = self.GRU_dropout(inputs)\n",
    "        init_state = self.init_GRU(batch_size)\n",
    "        outputs, states = self.GRU(inputs, init_state)\n",
    "        return outputs,states\n",
    "    \n",
    "\n",
    "    def Self_Attention(self, hidden_states, batch_size):\n",
    "        Attention_list = []\n",
    "        for i in range(6):\n",
    "            m1 = self.conv_att(torch.unsqueeze(hidden_states[:, i], dim=1))\n",
    "            Attention_list.append(torch.squeeze(m1, dim=2))\n",
    "        Attention_list = torch.stack(Attention_list, dim=2)\n",
    "        Attention_hops = []\n",
    "        for i in range(self.no_hops):\n",
    "            attention_single = self.softmax(Attention_list[:, i])\n",
    "            Attention_hops.append(attention_single)\n",
    "        Attention_hops = torch.stack(Attention_hops, dim=1)\n",
    "        output = torch.bmm(Attention_hops, hidden_states)\n",
    "        output = output.view(batch_size, -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, lab, vital, med, note_embed, MRI_embed_1, MRI_embed_2,MRI_embed_3,MRI_embed_4,MRI_embed_5, pt_demo, batch_size):\n",
    "        encoded_labs = self.lab_encoder(lab)\n",
    "        encoded_vital = self.vital_encoder(vital)\n",
    "        encoded_medAdmins = self.medAdmin_encoder(med)\n",
    "#         print(encoded_labs.shape)#  torch.Size([24, 300])\n",
    "#         print(encoded_vital.shape)#  torch.Size([24, 300])\n",
    "#         print(encoded_medAdmins.shape)#  torch.Size([24, 300])\n",
    "#         print(MRI_embed.shape)\n",
    "#         input()\n",
    "#         print(encoded_problems)\n",
    "        GRU_input=pad_sequence([\n",
    "#                                 torch.transpose(encoded_labs, 0, 1),\n",
    "#                                 torch.transpose(encoded_vital, 0, 1),\n",
    "#                                 torch.transpose(encoded_medAdmins, 0, 1), \n",
    "                                torch.transpose(note_embed, 0, 1), \n",
    "                                torch.transpose(MRI_embed_1, 0, 1), \n",
    "                                torch.transpose(MRI_embed_2, 0, 1), \n",
    "                                torch.transpose(MRI_embed_3, 0, 1), \n",
    "                                torch.transpose(MRI_embed_4, 0, 1), \n",
    "                                torch.transpose(MRI_embed_5, 0, 1), \n",
    "                               ])\n",
    "#         print(GRU_input.shape)# torch.Size([376, 5, 24])\n",
    "\n",
    "        GRU_input = torch.transpose(GRU_input, 0, 2)\n",
    "#         print(GRU_input.shape) # torch.Size([24, 5, 376])\n",
    "#         input(\"Stop here.\")\n",
    "        outputs_GRU,states_GRU = self.GRU_Decoder(GRU_input, batch_size)\n",
    "        GRU_out = self.Self_Attention(outputs_GRU, batch_size)\n",
    "        context = torch.cat((GRU_out, pt_demo), 1)\n",
    "        linear_y = self.linear(context)\n",
    "        out = self.sigmoid(linear_y)\n",
    "        return linear_y,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, preds):\n",
    "    roc_auc_macro = roc_auc_score(y_test, preds, average='macro')\n",
    "    roc_auc_micro = roc_auc_score(y_test, preds, average='micro')\n",
    "#     f1_macro= f1_score(y_test, preds, average='binary')\n",
    "#     f1_micro= f1_score(y_test, preds, average='micro')      \n",
    "    lr_precision, lr_recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "#     auprc = auc(lr_recall, lr_precision)\n",
    "    auprc = average_precision_score(y_test, preds)\n",
    "    f1_binary_best, f1_macro_best, f1_micro_best, thr_best = float('-inf'),float('-inf'), float('-inf'), 0\n",
    "    for thr in thresholds:\n",
    "        f1_binary, f1_macro, f1_micro = evaluate2(y_test, preds, thr)\n",
    "#         print(f1_macro, f1_micro, f1_macro_best, f1_micro_best)\n",
    "        if f1_binary > f1_binary_best or f1_macro > f1_macro_best or f1_micro > f1_micro_best:\n",
    "            f1_binary_best = f1_binary\n",
    "            f1_macro_best = f1_macro\n",
    "            f1_micro_best = f1_micro\n",
    "            thr_best = thr\n",
    "    print(\"AUC-Macro: {}, \\n AUC-Micro: {}, \\n AUPRC: {}, \\n F1-Binary: {}, \\n F1-Macro: {}, \\n F1-Micro: {}\".format(roc_auc_macro,roc_auc_micro, auprc, f1_binary_best, f1_macro_best, f1_micro_best)) # F1, F1))\n",
    "       \n",
    "def evaluate2(y_test, preds, thr):  \n",
    "    f1_binary= f1_score(y_test, preds>thr, average='binary')# 'macro')\n",
    "    f1_macro= f1_score(y_test, preds>thr, average='macro')\n",
    "    f1_micro= f1_score(y_test, preds>thr, average='micro') \n",
    "    return f1_binary, f1_macro, f1_micro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "import time\n",
    "EPOCHS = 500\n",
    "batch_size=24\n",
    "model=DBNet()\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "print(\"Starting Training of {} model\")\n",
    "# with open('performance.txt', 'a+') as f:\n",
    "#     f.write(\"Starting Training of {} model\\n\")\n",
    "epoch_times = []\n",
    "best_AUC=0\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    avg_loss = 0.\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "    for sample in dataloader:\n",
    "        lab, vital, medAdmin, note_embed, MRI_embed_1, MRI_embed_2, MRI_embed_3, MRI_embed_4, MRI_embed_5, pt_demo,label = sample\n",
    "        model.zero_grad()\n",
    "        one_hot_label = np.eye(2)[np.array(label,dtype=\"int\")]\n",
    "        one_hot_label = torch.tensor(one_hot_label)\n",
    "        label= torch.tensor(label).type(torch.long)\n",
    "        lab = lab.to(device)\n",
    "        vital = vital.to(device)\n",
    "        medAdmin = medAdmin.to(device)\n",
    "        note_embed = note_embed.to(device)\n",
    "        MRI_embed_1 = MRI_embed_1.to(device)\n",
    "        MRI_embed_2 = MRI_embed_2.to(device)\n",
    "        MRI_embed_3 = MRI_embed_3.to(device)\n",
    "        MRI_embed_4 = MRI_embed_4.to(device)\n",
    "        MRI_embed_5 = MRI_embed_5.to(device)\n",
    "        pt_demo = pt_demo.to(device)\n",
    "        counter += 1\n",
    "        out,predict=model(lab, vital, medAdmin, note_embed, MRI_embed_1, MRI_embed_2, MRI_embed_3, MRI_embed_4, MRI_embed_5, pt_demo,batch_size)\n",
    "        one_hot_label = one_hot_label.type_as(out).to(device)\n",
    "        loss = criterion(out, one_hot_label)\n",
    "        _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "    current_time = time.time()\n",
    "    print(\"Epoch {}/{} Done, Total Loss: {}, Accuracy : {} \".format(epoch, EPOCHS, avg_loss/len(dataloader),correct/total))\n",
    "    print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "#     with open('performance.txt', 'a+') as f:\n",
    "#         f.write(\"Epoch {}/{} Done, Total Loss: {}, Accuracy : {} \\n\".format(epoch, EPOCHS, avg_loss/len(dataloader),correct/total))\n",
    "#         f.write(\"Total Time Elapsed: {} seconds\\n\".format(str(current_time-start_time)))\n",
    "    epoch_times.append(current_time-start_time)\n",
    "    val_total=0\n",
    "    val_correct = 0\n",
    "    model.eval()\n",
    "    predicted_list=[]\n",
    "    prediction_probablity=[]\n",
    "    label_list = []\n",
    "    for sample in validation_loader:\n",
    "        lab,vital, medAdmin, note_embed, MRI_embed_1, MRI_embed_2, MRI_embed_3, MRI_embed_4, MRI_embed_5, pt_demo,label = sample\n",
    "        #model.zero_grad()\n",
    "        label= torch.tensor(label).type(torch.long)\n",
    "        lab = lab.to(device)\n",
    "        vital = vital.to(device)\n",
    "        medAdmin = medAdmin.to(device)\n",
    "        note_embed = note_embed.to(device)\n",
    "        MRI_embed_1 = MRI_embed_1.to(device)\n",
    "        MRI_embed_2 = MRI_embed_2.to(device)\n",
    "        MRI_embed_3 = MRI_embed_3.to(device)\n",
    "        MRI_embed_4 = MRI_embed_4.to(device)\n",
    "        MRI_embed_5 = MRI_embed_5.to(device)\n",
    "        pt_demo = pt_demo.to(device)\n",
    "        out,predict=model(lab,vital, medAdmin, note_embed, MRI_embed_1, MRI_embed_2, MRI_embed_3, MRI_embed_4, MRI_embed_5, pt_demo,batch_size)\n",
    "        _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "        predicted_list.append(predicted.cpu().numpy())\n",
    "        predicted_2 = predict.detach().cpu().numpy()\n",
    "        prediction_prob = predicted_2[:,1]\n",
    "        prediction_probablity.append(prediction_prob)\n",
    "        label_list.append(label.cpu().numpy())\n",
    "        val_total += label.size(0)\n",
    "        val_correct += (predicted == label).sum().item()\n",
    "    Accuracy = val_correct/val_total\n",
    "    y=np.array(label_list)\n",
    "    false_positive_rate, recall, thresholds = roc_curve(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    if roc_auc > best_AUC:\n",
    "        best_AUC = roc_auc\n",
    "        torch.save(model.state_dict(), \"Models_saved_DBNet_MRI_notes/State_checkpoints_{}.thr\".format(epoch))\n",
    "        torch.save(model, \"Models_saved_DBNet_MRI_notes/Model_checkpoints_{}.thr\".format(epoch))\n",
    "    print(\"AUC: {} , Accuracy: {}\".format(roc_auc,Accuracy))\n",
    "#     with open('performance.txt', 'a+') as f:\n",
    "#         f.write(\"AUC: {} , Accuracy: {}\\n\".format(roc_auc,Accuracy))\n",
    "print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "# with open('performance.txt', 'a+') as f:\n",
    "#     f.write(\"Total Training Time: {} seconds\\n\".format(str(sum(epoch_times))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### directly load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "import time\n",
    "model=DBNet()\n",
    "model.load_state_dict(torch.load(\"Models_saved_DBNet_MRI_notes/State_checkpoints_{}.thr\".format(56)))\n",
    "#torch.save(model, \"sssssssss/Model_checkpoints_{}.thr\".format(epoch))\n",
    "model = model.to(device)\n",
    "\n",
    "val_total=0\n",
    "val_correct = 0\n",
    "model.eval()\n",
    "predicted_list=[]\n",
    "prediction_probablity=[]\n",
    "label_list = []\n",
    "for sample in tqdm(validation_loader):\n",
    "    lab,vital, medAdmin, note_embed, MRI_embed_1, MRI_embed_2, MRI_embed_3, MRI_embed_4, MRI_embed_5, pt_demo,label = sample\n",
    "    #model.zero_grad()\n",
    "    label= torch.tensor(label).type(torch.long)\n",
    "    lab = lab.to(device)\n",
    "    vital = vital.to(device)\n",
    "    medAdmin = medAdmin.to(device)\n",
    "    note_embed = note_embed.to(device)\n",
    "    MRI_embed_1 = MRI_embed_1.to(device)\n",
    "    MRI_embed_2 = MRI_embed_2.to(device)\n",
    "    MRI_embed_3 = MRI_embed_3.to(device)\n",
    "    MRI_embed_4 = MRI_embed_4.to(device)\n",
    "    MRI_embed_5 = MRI_embed_5.to(device)\n",
    "    pt_demo = pt_demo.to(device)\n",
    "    out,predict=model(lab,vital, medAdmin, note_embed, MRI_embed_1, MRI_embed_2, MRI_embed_3, MRI_embed_4, MRI_embed_5, pt_demo,batch_size)\n",
    "#     print(predict)\n",
    "    _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "#     print(predicted)\n",
    "    predicted_list.append(predicted.cpu().numpy())\n",
    "#     print(predicted_list)\n",
    "    predicted_2 = predict.detach().cpu().numpy()\n",
    "#     print(predicted_2)\n",
    "    prediction_prob = predicted_2[:,1]\n",
    "#     print(prediction_prob)\n",
    "    prediction_probablity.append(prediction_prob)\n",
    "    label_list.append(label.cpu().numpy())\n",
    "#     print(label_list)\n",
    "    val_total += label.size(0)\n",
    "    val_correct += (predicted == label).sum().item()\n",
    "Accuracy = val_correct/val_total\n",
    "y=np.array(label_list)\n",
    "false_positive_rate, recall, thresholds = roc_curve(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "# auprc = auc(lr_recall, lr_precision)\n",
    "\n",
    "auprc = average_precision_score(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "print(\"AUC: {} , Accuracy: {}, AUPRC: {}\".format(roc_auc,Accuracy,auprc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y.flatten(), np.array(prediction_probablity).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix , auc, precision_recall_curve, average_precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    false_positive_rate, recall, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    auprc = average_precision_score(y_true, y_pred)\n",
    "    print('AUC: ',roc_auc, \"AUPRC: \", auprc)\n",
    "\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "\n",
    "    # calculate the g-mean for each threshold\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred > thresholds[ix]).ravel()\n",
    "    print('TN: ', tn, \", FP: \",fp, \", FN:\", fn, \", TP:\", tp)\n",
    "    print(\"==> Sensitivity (Recall, TPR): %.3f\"%(tp/(tp+fn)))\n",
    "    print(\"==> Specifity: %.3f\"%(tn/(tn+fp)))\n",
    "    print(\"==> Positive Predictive Value (PPV) (Precision): %.3f\"%(tp / (tp + fp)))\n",
    "    print(\"==> Negative Predictive Value (NPV): %.3f\"%(tn / (tn + fn)))\n",
    "    print(\"==> Accuracy: %.3f\"%((tp+tn)/(tn+ fp+ fn+tp)))\n",
    "    print(\"==> F1 score: %.3f\"%((2*tp)/(2*tp + fp + fn)))\n",
    "    \n",
    "    # method I: plt\n",
    "#     fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "#     plt.legend(loc = 'lower right')\n",
    "#     plt.plot([0, 1], [0, 1],'r--')\n",
    "#     plt.xlim([0, 1])\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.show()\n",
    "    ns_probs = [0 for _ in range(len(y_true))]\n",
    "    \n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_true, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_true, y_pred)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill, AUC = %0.2f' % 0.5)\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label = 'Our model: AUC = %0.2f' % roc_auc)\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    lr_auc = auc(lr_recall, lr_precision)\n",
    "    # summarize scores\n",
    "#     print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "    # plot the precision-recall curves\n",
    "    y_true = np.array(y_true)\n",
    "    no_skill = len(y_true[y_true==1]) / len(y_true)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No skill, AUPRC = %0.2f' % no_skill)\n",
    "    plt.plot(lr_recall, lr_precision, marker='.',label = 'Our model: AUPRC = %0.2f' % auprc)\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend(loc = 'upper right')\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(np.array([1]*1421+[0]*(10882-1421)), np.random.random((10882,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y.flatten(), np.array(prediction_probablity).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
