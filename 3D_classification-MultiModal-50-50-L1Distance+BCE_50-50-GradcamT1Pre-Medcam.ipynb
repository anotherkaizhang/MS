{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use 2 modal: T1-pre, T1-post\n",
    "- batch_size=10\n",
    "- smaller network\n",
    "- Data Augmentation (10*positive samples)\n",
    "- minimize L1 distance + BCE loss\n",
    "- train-test: 50% -50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581\n"
     ]
    }
   ],
   "source": [
    "with open('MRI_Image_TO_EDSS', 'rb') as f:\n",
    "    MRI_Image_TO_EDSS = pickle.load(f)\n",
    "print(len(MRI_Image_TO_EDSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346 346 346 346 346\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "346\n"
     ]
    }
   ],
   "source": [
    "images_T1_post = []\n",
    "images_T1_pre = []\n",
    "images_T2 = []\n",
    "images_flair  = []\n",
    "\n",
    "labels = [] # np.array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0], dtype=np.int64)\n",
    "MRIs = []\n",
    "\n",
    "for i in range(len(MRI_Image_TO_EDSS)):\n",
    "    MRI_Image = str(int(MRI_Image_TO_EDSS[i][0]))\n",
    "    if MRI_Image not in os.listdir('./img_debias'):\n",
    "        continue\n",
    "    if len(os.listdir(os.sep.join([\"img_debias\", MRI_Image]))) != 5:\n",
    "        continue\n",
    "        \n",
    "    ### T1 Post\n",
    "    data_path_T1_post = os.sep.join([\"img_debias\", MRI_Image, \"t1_post_reg_des_debis.nii.gz\"])\n",
    "    images_T1_post.append(data_path_T1_post)\n",
    "    \n",
    "    ### T1 Pre\n",
    "    data_path_T1_pre = os.sep.join([\"img_debias\", MRI_Image, \"t1_pre_reg_des_debis.nii.gz\"])\n",
    "    images_T1_pre.append(data_path_T1_pre)\n",
    "    \n",
    "    ### T2 \n",
    "    data_path_T2 = os.sep.join([\"img_debias\", MRI_Image, \"t2_reg_des_debis.nii.gz\"])\n",
    "    images_T2.append(data_path_T2)\n",
    "\n",
    "    ### flair\n",
    "    data_path_flair= os.sep.join([\"img_debias\", MRI_Image, \"flair_reg_des_debis.nii.gz\"])\n",
    "    images_flair.append(data_path_flair)\n",
    "    \n",
    "    labels.append(int(MRI_Image_TO_EDSS[i][1] > 4.0))\n",
    "    MRIs.append(MRI_Image)\n",
    "print(len(images_T1_post), len(images_T1_pre),len(images_T2), len(images_flair), len(labels))\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "# data_path = os.sep.join([\"../../\", \"workspace\", \"data\", \"medical\", \"ixi\", \"IXI-T1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>Train set size:\n",
      "353 353 353 353 353\n",
      "=======> # positives in Train\n",
      "198\n",
      "====>Test set size:\n",
      "173 173 173 173 173\n",
      "=======> # positives in Test\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "##  shuffle first\n",
    "randinds = np.arange(len(labels))\n",
    "np.random.seed(42) \n",
    "np.random.shuffle(randinds)\n",
    "\n",
    "MRIs = [MRIs[i] for i in randinds]\n",
    "labels = [labels[i] for i in randinds]\n",
    "images_T1_post = [images_T1_post[i] for i in randinds]\n",
    "images_T1_pre = [images_T1_pre[i] for i in randinds]\n",
    "images_T2 = [images_T2[i] for i in randinds]\n",
    "images_flair = [images_flair[i] for i in randinds]\n",
    "\n",
    "## split train /test\n",
    "train_frac = 0.5\n",
    "Ntot = len(labels)\n",
    "\n",
    "cut = int(train_frac * Ntot)\n",
    "\n",
    "MRIs_train = MRIs[: cut]\n",
    "MRIs_test = MRIs[cut:]  ### FUCK!!! wrong here...\n",
    "labels_train = labels[: cut]\n",
    "labels_test = labels[cut :]\n",
    "images_T1_post_train = images_T1_post[: cut]\n",
    "images_T1_post_test = images_T1_post[cut :]\n",
    "images_T1_pre_train  = images_T1_pre[: cut]\n",
    "images_T1_pre_test  = images_T1_pre[cut :]\n",
    "images_T2_train  = images_T2[: cut]\n",
    "images_T2_test  = images_T2[cut :]\n",
    "images_flair_train = images_flair[: cut]\n",
    "images_flair_test = images_flair[cut :]\n",
    "\n",
    "## Augment train only\n",
    "inds = [i for i, x in enumerate(labels_train) if x ==1]\n",
    "MRIs_train.extend([MRIs_train[i] for i in inds]*10)\n",
    "labels_train.extend([labels_train[i] for i in inds]*10)\n",
    "images_T1_post_train.extend([images_T1_post_train[i] for i in inds]*10)\n",
    "images_T1_pre_train.extend([images_T1_pre_train[i] for i in inds]*10)\n",
    "images_T2_train.extend([images_T2_train[i] for i in inds]*10)\n",
    "images_flair_train.extend([images_flair_train[i] for i in inds]*10)\n",
    "\n",
    "##  shuffle train again\n",
    "randinds = np.arange(len(labels_train))\n",
    "np.random.seed(42) \n",
    "np.random.shuffle(randinds)\n",
    "MRIs_train = [MRIs_train[i] for i in randinds]\n",
    "labels_train = [labels_train[i] for i in randinds]\n",
    "images_T1_post_train = [images_T1_post_train[i] for i in randinds]\n",
    "images_T1_pre_train = [images_T1_pre_train[i] for i in randinds]\n",
    "images_T2_train = [images_T2_train[i] for i in randinds]\n",
    "images_flair_train = [images_flair_train[i] for i in randinds]\n",
    "\n",
    "print('====>Train set size:')\n",
    "print(len(images_T1_post_train), len(images_T1_pre_train),len(images_T2_train), \n",
    "      len(images_flair_train), len(labels_train))\n",
    "print('=======> # positives in Train')\n",
    "print(np.sum(labels_train))\n",
    "print('====>Test set size:')\n",
    "print(len(images_T1_post_test), len(images_T1_pre_test),len(images_T2_test), \n",
    "      len(images_flair_test), len(labels_test))\n",
    "print('=======> # positives in Test')\n",
    "print(np.sum(labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 173, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(MRIs_train)), len(set(MRIs_test)), \\\n",
    "len(set(MRIs_train).intersection(MRIs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set label weight  in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [155, 198]\n",
      "tensor([0.0065, 0.0051])\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(labels_train))\n",
    "class_count = [np.sum(np.array(labels_train) == i ) for i in range(num_classes)]\n",
    "print(num_classes, class_count)\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 353)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels_train), len(labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix , auc, precision_recall_curve, average_precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    false_positive_rate, recall, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    auprc = average_precision_score(y_true, y_pred)\n",
    "    print('AUC: ',roc_auc, \"AUPRC: \", auprc)\n",
    "\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "\n",
    "    # calculate the g-mean for each threshold\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred > thresholds[ix]).ravel()\n",
    "    print('TN: ', tn, \", FP: \",fp, \", FN:\", fn, \", TP:\", tp)\n",
    "    print(\"==> Sensitivity (Recall, TPR): %.3f\"%(tp/(tp+fn)))\n",
    "    print(\"==> Specifity: %.3f\"%(tn/(tn+fp)))\n",
    "    print(\"==> Positive Predictive Value (PPV) (Precision): %.3f\"%(tp / (tp + fp)))\n",
    "    print(\"==> Negative Predictive Value (NPV): %.3f\"%(tn / (tn + fn)))\n",
    "    print(\"==> Accuracy: %.3f\"%((tp+tn)/(tn+ fp+ fn+tp)))\n",
    "    print(\"==> F1 score: %.3f\"%((2*tp)/(2*tp + fp + fn)))\n",
    "    \n",
    "    ns_probs = [0 for _ in range(len(y_true))]\n",
    "    \n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_true, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_true, y_pred)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill, AUC = %0.2f' % 0.5)\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label = 'Our model: AUC = %0.2f' % roc_auc)\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    lr_auc = auc(lr_recall, lr_precision)\n",
    "    # summarize scores\n",
    "#     print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "    # plot the precision-recall curves\n",
    "    y_true = np.array(y_true)\n",
    "    no_skill = len(y_true[y_true==1]) / len(y_true)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No skill, AUPRC = %0.2f' % no_skill)\n",
    "    plt.plot(lr_recall, lr_precision, marker='.',label = 'Our model: AUPRC = %0.2f' % auprc)\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend(loc = 'upper right')\n",
    "    # show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from typing import Callable, Sequence, Type, Union\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from monai.networks.layers.factories import Conv, Dropout, Pool\n",
    "from monai.networks.layers.utils import get_act_layer, get_norm_layer\n",
    "from monai.utils.module import look_up_option\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            in_channels: number of the input channel.\n",
    "            out_channels: number of the output classes.\n",
    "            act: activation type and arguments. Defaults to relu.\n",
    "            norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        pool_type: Callable = Pool[Pool.AVG, spatial_dims]\n",
    "\n",
    "        self.add_module(\"norm\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=in_channels))\n",
    "        self.add_module(\"relu\", get_act_layer(name=act))\n",
    "        self.add_module(\"conv\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "        self.add_module(\"pool\", pool_type(kernel_size=2, stride=2))\n",
    "\n",
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        growth_rate: int,\n",
    "        bn_size: int,\n",
    "        dropout_prob: float,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            in_channels: number of the input channel.\n",
    "            growth_rate: how many filters to add each layer (k in paper).\n",
    "            bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                (i.e. bn_size * k features in the bottleneck layer)\n",
    "            dropout_prob: dropout rate after each dense layer.\n",
    "            act: activation type and arguments. Defaults to relu.\n",
    "            norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        out_channels = bn_size * growth_rate\n",
    "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
    "        dropout_type: Callable = Dropout[Dropout.DROPOUT, spatial_dims]\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "\n",
    "        self.layers.add_module(\"norm1\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=in_channels))\n",
    "        self.layers.add_module(\"relu1\", get_act_layer(name=act))\n",
    "        self.layers.add_module(\"conv1\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n",
    "\n",
    "        self.layers.add_module(\"norm2\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=out_channels))\n",
    "        self.layers.add_module(\"relu2\", get_act_layer(name=act))\n",
    "        self.layers.add_module(\"conv2\", conv_type(out_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n",
    "\n",
    "        if dropout_prob > 0:\n",
    "            self.layers.add_module(\"dropout\", dropout_type(dropout_prob))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        new_features = self.layers(x)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "    \n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        layers: int,\n",
    "        in_channels: int,\n",
    "        bn_size: int,\n",
    "        growth_rate: int,\n",
    "        dropout_prob: float,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions of the input image.\n",
    "            layers: number of layers in the block.\n",
    "            in_channels: number of the input channel.\n",
    "            bn_size: multiplicative factor for number of bottle neck layers.\n",
    "                (i.e. bn_size * k features in the bottleneck layer)\n",
    "            growth_rate: how many filters to add each layer (k in paper).\n",
    "            dropout_prob: dropout rate after each dense layer.\n",
    "            act: activation type and arguments. Defaults to relu.\n",
    "            norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        for i in range(layers):\n",
    "            layer = _DenseLayer(spatial_dims, in_channels, growth_rate, bn_size, dropout_prob, act=act, norm=norm)\n",
    "            in_channels += growth_rate\n",
    "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
    "            \n",
    "class DenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Densenet based on: `Densely Connected Convolutional Networks <https://arxiv.org/pdf/1608.06993.pdf>`_.\n",
    "    Adapted from PyTorch Hub 2D version: https://pytorch.org/vision/stable/models.html#id16.\n",
    "    Args:\n",
    "        spatial_dims: number of spatial dimensions of the input image.\n",
    "        in_channels: number of the input channel.\n",
    "        out_channels: number of the output classes.\n",
    "        init_features: number of filters in the first convolution layer.\n",
    "        growth_rate: how many filters to add each layer (k in paper).\n",
    "        block_config: how many layers in each pooling block.\n",
    "        bn_size: multiplicative factor for number of bottle neck layers.\n",
    "            (i.e. bn_size * k features in the bottleneck layer)\n",
    "        act: activation type and arguments. Defaults to relu.\n",
    "        norm: feature normalization type and arguments. Defaults to batch norm.\n",
    "        dropout_prob: dropout rate after each dense layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        init_features: int = 64,\n",
    "        growth_rate: int = 32,\n",
    "        block_config: Sequence[int] = (6, 12, 24, 16),\n",
    "        bn_size: int = 4,\n",
    "        act: Union[str, tuple] = (\"relu\", {\"inplace\": False}),\n",
    "        norm: Union[str, tuple] = \"batch\",\n",
    "        dropout_prob: float = 0.0,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        conv_type: Type[Union[nn.Conv1d, nn.Conv2d, nn.Conv3d]] = Conv[Conv.CONV, spatial_dims]\n",
    "        pool_type: Type[Union[nn.MaxPool1d, nn.MaxPool2d, nn.MaxPool3d]] = Pool[Pool.MAX, spatial_dims]\n",
    "        avg_pool_type: Type[Union[nn.AdaptiveAvgPool1d, nn.AdaptiveAvgPool2d, nn.AdaptiveAvgPool3d]] = Pool[\n",
    "            Pool.ADAPTIVEAVG, spatial_dims\n",
    "        ]\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv0\", conv_type(in_channels, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                    (\"norm0\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=init_features)),\n",
    "                    (\"relu0\", get_act_layer(name=act)),\n",
    "                    (\"pool0\", pool_type(kernel_size=3, stride=2, padding=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_channels = init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                spatial_dims=spatial_dims,\n",
    "                layers=num_layers,\n",
    "                in_channels=in_channels,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                dropout_prob=dropout_prob,\n",
    "                act=act,\n",
    "                norm=norm,\n",
    "            )\n",
    "            self.features.add_module(f\"denseblock{i + 1}\", block)\n",
    "            in_channels += num_layers * growth_rate\n",
    "#             print('in_channels is ', in_channels)\n",
    "            if i == len(block_config) - 1:\n",
    "                self.features.add_module(\n",
    "                    \"norm5\", get_norm_layer(name=norm, spatial_dims=spatial_dims, channels=in_channels)\n",
    "                )\n",
    "            else:\n",
    "                _out_channels = in_channels // 2\n",
    "                trans = _Transition(\n",
    "                    spatial_dims, in_channels=in_channels, out_channels=_out_channels, act=act, norm=norm\n",
    "                )\n",
    "                self.features.add_module(f\"transition{i + 1}\", trans)\n",
    "                in_channels = _out_channels\n",
    "\n",
    "        # pooling and classification\n",
    "        self.class_layers = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"relu\", get_act_layer(name=act)),\n",
    "                    (\"pool\", avg_pool_type(1)),\n",
    "                    (\"flatten\", nn.Flatten(1)),\n",
    "                    (\"out\", nn.Linear(in_channels, out_channels)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        ### get them out\n",
    "        self.class_layers_1 = get_act_layer(name=act)\n",
    "        self.class_layers_2 = avg_pool_type(1)\n",
    "        self.class_layers_3 = nn.Flatten(1)\n",
    "        MODAL = 1\n",
    "        self.class_layers_4 = nn.Linear(in_channels * MODAL, out_channels)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, conv_type):\n",
    "                nn.init.kaiming_normal_(torch.as_tensor(m.weight))\n",
    "            elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "                nn.init.constant_(torch.as_tensor(m.weight), 1)\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "\n",
    "        \n",
    "    def forward(self, x_T1_pre: torch.Tensor\n",
    "                   ) -> torch.Tensor:   # [2, 1, 96, 96, 96]\n",
    "        ####  ==================== T1_pre ==================================\n",
    "        x_T1_pre = self.features(x_T1_pre)    # [2, 1024, 3, 3, 3]\n",
    "        x_T1_pre = self.class_layers_1(x_T1_pre)  # output: [2, 1024, 3, 3, 3]\n",
    "        x_T1_pre = self.class_layers_2(x_T1_pre) # output: [2, 1024, 1, 1, 1]\n",
    "        x_T1_pre = self.class_layers_3(x_T1_pre) # output: [2, 1024]\n",
    "        x_join = x_T1_pre\n",
    "        linear_y = self.class_layers_4(x_join) # output: [2, 2]\n",
    "        out = self.sigmoid(linear_y)\n",
    "        return x_join, linear_y , out\n",
    "\n",
    "    \n",
    "class DenseNet121(DenseNet):\n",
    "    \"\"\"DenseNet121 with optional pretrained support when `spatial_dims` is 2.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_features: int = 32, # 64,\n",
    "        growth_rate: int = 16, # 32,\n",
    "        block_config: Sequence[int] = (3,6,12,8),#(6, 12, 24, 16),\n",
    "        pretrained: bool = False,\n",
    "        progress: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(init_features=init_features, growth_rate=growth_rate, block_config=block_config, **kwargs)\n",
    "        if pretrained:\n",
    "            if kwargs[\"spatial_dims\"] > 2:\n",
    "                raise NotImplementedError(\n",
    "                    \"Parameter `spatial_dims` is > 2 ; currently PyTorch Hub does not\"\n",
    "                    \"provide pretrained models for more than two spatial dimensions.\"\n",
    "                )\n",
    "            _load_state_dict(self, \"densenet121\", progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/400\n",
      "epoch 1 average loss: 25.9585\n",
      "----------\n",
      "epoch 2/400\n",
      "epoch 2 average loss: 21.3993\n",
      "AUC: 0.4126582278481013 , Accuracy: 0.2658959537572254, AUPRC: 0.08529685278372856\n",
      "----------\n",
      "epoch 3/400\n",
      "epoch 3 average loss: 17.9931\n",
      "----------\n",
      "epoch 4/400\n",
      "epoch 4 average loss: 14.8011\n",
      "AUC: 0.41772151898734183 , Accuracy: 0.19653179190751446, AUPRC: 0.09014166925158482\n",
      "----------\n",
      "epoch 5/400\n",
      "epoch 5 average loss: 11.7237\n",
      "----------\n",
      "epoch 6/400\n",
      "epoch 6 average loss: 8.9350\n",
      "AUC: 0.4312236286919831 , Accuracy: 0.24277456647398843, AUPRC: 0.09083613853434536\n",
      "----------\n",
      "epoch 7/400\n",
      "epoch 7 average loss: 6.5952\n",
      "----------\n",
      "epoch 8/400\n",
      "epoch 8 average loss: 4.7463\n",
      "AUC: 0.4594936708860759 , Accuracy: 0.3468208092485549, AUPRC: 0.09836834344347312\n",
      "----------\n",
      "epoch 9/400\n",
      "epoch 9 average loss: 3.3371\n",
      "----------\n",
      "epoch 10/400\n",
      "epoch 10 average loss: 2.3353\n",
      "AUC: 0.4130801687763713 , Accuracy: 0.4797687861271676, AUPRC: 0.07913800844624533\n",
      "----------\n",
      "epoch 11/400\n",
      "epoch 11 average loss: 1.6216\n",
      "----------\n",
      "epoch 12/400\n",
      "epoch 12 average loss: 1.1475\n",
      "AUC: 0.4286919831223629 , Accuracy: 0.7052023121387283, AUPRC: 0.08221881353891827\n",
      "----------\n",
      "epoch 13/400\n",
      "epoch 13 average loss: 0.8313\n",
      "----------\n",
      "epoch 14/400\n",
      "epoch 14 average loss: 0.6301\n",
      "AUC: 0.4734177215189873 , Accuracy: 0.815028901734104, AUPRC: 0.09622025732851164\n",
      "----------\n",
      "epoch 15/400\n",
      "epoch 15 average loss: 0.4746\n",
      "----------\n",
      "epoch 16/400\n",
      "epoch 16 average loss: 0.3296\n",
      "AUC: 0.5033755274261603 , Accuracy: 0.8670520231213873, AUPRC: 0.10170332990700984\n",
      "----------\n",
      "epoch 17/400\n",
      "epoch 17 average loss: 0.2060\n",
      "----------\n",
      "epoch 18/400\n",
      "epoch 18 average loss: 0.1066\n",
      "AUC: 0.5210970464135021 , Accuracy: 0.8786127167630058, AUPRC: 0.10550182430925681\n",
      "----------\n",
      "epoch 19/400\n",
      "epoch 19 average loss: 0.0568\n",
      "----------\n",
      "epoch 20/400\n",
      "epoch 20 average loss: 0.0331\n",
      "AUC: 0.5417721518987342 , Accuracy: 0.884393063583815, AUPRC: 0.11686862556570005\n",
      "----------\n",
      "epoch 21/400\n",
      "epoch 21 average loss: 0.0229\n",
      "----------\n",
      "epoch 22/400\n",
      "epoch 22 average loss: 0.0093\n",
      "AUC: 0.5485232067510549 , Accuracy: 0.884393063583815, AUPRC: 0.11809460217284129\n",
      "----------\n",
      "epoch 23/400\n",
      "epoch 23 average loss: 0.0037\n",
      "----------\n",
      "epoch 24/400\n",
      "epoch 24 average loss: 0.0037\n",
      "AUC: 0.5611814345991561 , Accuracy: 0.8901734104046243, AUPRC: 0.11287543198140204\n",
      "----------\n",
      "epoch 25/400\n",
      "epoch 25 average loss: 0.0037\n",
      "----------\n",
      "epoch 26/400\n",
      "epoch 26 average loss: 0.0037\n",
      "AUC: 0.5687763713080168 , Accuracy: 0.8959537572254336, AUPRC: 0.11263091614258708\n",
      "----------\n",
      "epoch 27/400\n",
      "epoch 27 average loss: 0.0037\n",
      "----------\n",
      "epoch 28/400\n",
      "epoch 28 average loss: 0.0036\n",
      "AUC: 0.5746835443037974 , Accuracy: 0.9017341040462428, AUPRC: 0.11342496343172107\n",
      "----------\n",
      "epoch 29/400\n",
      "epoch 29 average loss: 0.0036\n",
      "----------\n",
      "epoch 30/400\n",
      "epoch 30 average loss: 0.0036\n",
      "AUC: 0.5890295358649789 , Accuracy: 0.9017341040462428, AUPRC: 0.1182516677621567\n",
      "----------\n",
      "epoch 31/400\n",
      "epoch 31 average loss: 0.0036\n",
      "----------\n",
      "epoch 32/400\n",
      "epoch 32 average loss: 0.0036\n",
      "AUC: 0.5962025316455697 , Accuracy: 0.9075144508670521, AUPRC: 0.12076523737931252\n",
      "----------\n",
      "epoch 33/400\n",
      "epoch 33 average loss: 0.0036\n",
      "----------\n",
      "epoch 34/400\n",
      "epoch 34 average loss: 0.0036\n",
      "AUC: 0.6046413502109704 , Accuracy: 0.9075144508670521, AUPRC: 0.1232436118210865\n",
      "----------\n",
      "epoch 35/400\n",
      "epoch 35 average loss: 0.0036\n",
      "----------\n",
      "epoch 36/400\n",
      "epoch 36 average loss: 0.0036\n",
      "AUC: 0.6075949367088608 , Accuracy: 0.9132947976878613, AUPRC: 0.12403748350748316\n",
      "----------\n",
      "epoch 37/400\n",
      "epoch 37 average loss: 0.0036\n",
      "----------\n",
      "epoch 38/400\n",
      "epoch 38 average loss: 0.0036\n",
      "AUC: 0.6118143459915613 , Accuracy: 0.9132947976878613, AUPRC: 0.12583869104839823\n",
      "----------\n",
      "epoch 39/400\n",
      "epoch 39 average loss: 0.0036\n",
      "----------\n",
      "epoch 40/400\n",
      "epoch 40 average loss: 0.0036\n",
      "AUC: 0.6139240506329113 , Accuracy: 0.9132947976878613, AUPRC: 0.12621068878299743\n",
      "----------\n",
      "epoch 41/400\n",
      "epoch 41 average loss: 0.0036\n",
      "----------\n",
      "epoch 42/400\n",
      "epoch 42 average loss: 0.0036\n",
      "AUC: 0.6185654008438819 , Accuracy: 0.9132947976878613, AUPRC: 0.1276706961538061\n",
      "----------\n",
      "epoch 43/400\n",
      "epoch 43 average loss: 0.0036\n",
      "----------\n",
      "epoch 44/400\n",
      "epoch 44 average loss: 0.0036\n",
      "AUC: 0.6206751054852321 , Accuracy: 0.9132947976878613, AUPRC: 0.12748024606279276\n",
      "----------\n",
      "epoch 45/400\n",
      "epoch 45 average loss: 0.0036\n",
      "----------\n",
      "epoch 46/400\n",
      "epoch 46 average loss: 0.0035\n",
      "AUC: 0.6253164556962025 , Accuracy: 0.9132947976878613, AUPRC: 0.13021066948586302\n",
      "----------\n",
      "epoch 47/400\n",
      "epoch 47 average loss: 0.0035\n",
      "----------\n",
      "epoch 48/400\n",
      "epoch 48 average loss: 0.0035\n",
      "AUC: 0.6274261603375527 , Accuracy: 0.9132947976878613, AUPRC: 0.1309046647043739\n",
      "----------\n",
      "epoch 49/400\n",
      "epoch 49 average loss: 0.0035\n",
      "----------\n",
      "epoch 50/400\n",
      "epoch 50 average loss: 0.0035\n",
      "AUC: 0.6324894514767933 , Accuracy: 0.9132947976878613, AUPRC: 0.13290426203212047\n",
      "----------\n",
      "epoch 51/400\n",
      "epoch 51 average loss: 0.0035\n",
      "----------\n",
      "epoch 52/400\n",
      "epoch 52 average loss: 0.0035\n",
      "AUC: 0.6329113924050632 , Accuracy: 0.9132947976878613, AUPRC: 0.13378406019519143\n",
      "----------\n",
      "epoch 53/400\n",
      "epoch 53 average loss: 0.0035\n",
      "----------\n",
      "epoch 54/400\n",
      "epoch 54 average loss: 0.0035\n",
      "AUC: 0.6375527426160338 , Accuracy: 0.9132947976878613, AUPRC: 0.13499816444893145\n",
      "----------\n",
      "epoch 55/400\n",
      "epoch 55 average loss: 0.0035\n",
      "----------\n",
      "epoch 56/400\n",
      "epoch 56 average loss: 0.0035\n",
      "AUC: 0.6379746835443038 , Accuracy: 0.9132947976878613, AUPRC: 0.135787039887723\n",
      "----------\n",
      "epoch 57/400\n",
      "epoch 57 average loss: 0.0035\n",
      "----------\n",
      "epoch 58/400\n",
      "epoch 58 average loss: 0.0035\n",
      "AUC: 0.6400843881856539 , Accuracy: 0.9132947976878613, AUPRC: 0.13643169529070373\n",
      "----------\n",
      "epoch 59/400\n",
      "epoch 59 average loss: 0.0035\n",
      "----------\n",
      "epoch 60/400\n",
      "epoch 60 average loss: 0.0035\n",
      "AUC: 0.6409282700421941 , Accuracy: 0.9132947976878613, AUPRC: 0.13626430696803735\n",
      "----------\n",
      "epoch 61/400\n",
      "epoch 61 average loss: 0.0035\n",
      "----------\n",
      "epoch 62/400\n",
      "epoch 62 average loss: 0.0035\n",
      "AUC: 0.6430379746835443 , Accuracy: 0.9132947976878613, AUPRC: 0.1373232036543273\n",
      "----------\n",
      "epoch 63/400\n",
      "epoch 63 average loss: 0.0035\n",
      "----------\n",
      "epoch 64/400\n",
      "epoch 64 average loss: 0.0034\n",
      "AUC: 0.6455696202531646 , Accuracy: 0.9132947976878613, AUPRC: 0.13795256535322065\n",
      "----------\n",
      "epoch 65/400\n",
      "epoch 65 average loss: 0.0034\n",
      "----------\n",
      "epoch 66/400\n",
      "epoch 66 average loss: 0.0034\n",
      "AUC: 0.6493670886075948 , Accuracy: 0.9132947976878613, AUPRC: 0.13953593055689437\n",
      "----------\n",
      "epoch 67/400\n",
      "epoch 67 average loss: 0.0034\n",
      "----------\n",
      "epoch 68/400\n",
      "epoch 68 average loss: 0.0034\n",
      "AUC: 0.6493670886075948 , Accuracy: 0.9132947976878613, AUPRC: 0.13986558717416786\n",
      "----------\n",
      "epoch 69/400\n",
      "epoch 69 average loss: 0.0034\n",
      "----------\n",
      "epoch 70/400\n",
      "epoch 70 average loss: 0.0034\n",
      "AUC: 0.6485232067510549 , Accuracy: 0.9132947976878613, AUPRC: 0.13879155049538797\n",
      "----------\n",
      "epoch 71/400\n",
      "epoch 71 average loss: 0.0034\n",
      "----------\n",
      "epoch 72/400\n",
      "epoch 72 average loss: 0.0034\n",
      "AUC: 0.6489451476793249 , Accuracy: 0.9132947976878613, AUPRC: 0.1392978356840624\n",
      "----------\n",
      "epoch 73/400\n",
      "epoch 73 average loss: 0.0034\n",
      "----------\n",
      "epoch 74/400\n",
      "epoch 74 average loss: 0.0034\n",
      "AUC: 0.6510548523206752 , Accuracy: 0.9132947976878613, AUPRC: 0.14079111452244283\n",
      "----------\n",
      "epoch 75/400\n",
      "epoch 75 average loss: 0.0034\n",
      "----------\n",
      "epoch 76/400\n",
      "epoch 76 average loss: 0.0034\n",
      "AUC: 0.6518987341772151 , Accuracy: 0.9132947976878613, AUPRC: 0.14215131305767226\n",
      "----------\n",
      "epoch 77/400\n",
      "epoch 77 average loss: 0.0034\n",
      "----------\n",
      "epoch 78/400\n",
      "epoch 78 average loss: 0.0034\n",
      "AUC: 0.6527426160337553 , Accuracy: 0.9132947976878613, AUPRC: 0.14246942773608226\n",
      "----------\n",
      "epoch 79/400\n",
      "epoch 79 average loss: 0.0034\n",
      "----------\n",
      "epoch 80/400\n",
      "epoch 80 average loss: 0.0034\n",
      "AUC: 0.6527426160337553 , Accuracy: 0.9132947976878613, AUPRC: 0.1419446741572702\n",
      "----------\n",
      "epoch 81/400\n",
      "epoch 81 average loss: 0.0034\n",
      "----------\n",
      "epoch 82/400\n",
      "epoch 82 average loss: 0.0034\n",
      "AUC: 0.6518987341772152 , Accuracy: 0.9132947976878613, AUPRC: 0.14105016145274468\n",
      "----------\n",
      "epoch 83/400\n",
      "epoch 83 average loss: 0.0034\n",
      "----------\n",
      "epoch 84/400\n",
      "epoch 84 average loss: 0.0033\n",
      "AUC: 0.6527426160337553 , Accuracy: 0.9132947976878613, AUPRC: 0.1412070241978427\n",
      "----------\n",
      "epoch 85/400\n",
      "epoch 85 average loss: 0.0033\n",
      "----------\n",
      "epoch 86/400\n",
      "epoch 86 average loss: 0.0033\n",
      "AUC: 0.6544303797468354 , Accuracy: 0.9132947976878613, AUPRC: 0.14211378630126523\n",
      "----------\n",
      "epoch 87/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87 average loss: 0.0033\n",
      "----------\n",
      "epoch 88/400\n",
      "epoch 88 average loss: 0.0033\n",
      "AUC: 0.6552742616033755 , Accuracy: 0.9132947976878613, AUPRC: 0.14258714931962074\n",
      "----------\n",
      "epoch 89/400\n",
      "epoch 89 average loss: 0.0033\n",
      "----------\n",
      "epoch 90/400\n",
      "epoch 90 average loss: 0.0033\n",
      "AUC: 0.6561181434599156 , Accuracy: 0.9132947976878613, AUPRC: 0.14281968818748073\n",
      "----------\n",
      "epoch 91/400\n",
      "epoch 91 average loss: 0.0033\n",
      "----------\n",
      "epoch 92/400\n",
      "epoch 92 average loss: 0.0033\n",
      "AUC: 0.6573839662447257 , Accuracy: 0.9132947976878613, AUPRC: 0.1428815756640422\n",
      "----------\n",
      "epoch 93/400\n",
      "epoch 93 average loss: 0.0033\n",
      "----------\n",
      "epoch 94/400\n",
      "epoch 94 average loss: 0.0033\n",
      "AUC: 0.6582278481012658 , Accuracy: 0.9132947976878613, AUPRC: 0.143448951550567\n",
      "----------\n",
      "epoch 95/400\n",
      "epoch 95 average loss: 0.0033\n",
      "----------\n",
      "epoch 96/400\n",
      "epoch 96 average loss: 0.0033\n",
      "AUC: 0.6594936708860759 , Accuracy: 0.9132947976878613, AUPRC: 0.1441517928832895\n",
      "----------\n",
      "epoch 97/400\n",
      "epoch 97 average loss: 0.0033\n",
      "----------\n",
      "epoch 98/400\n",
      "epoch 98 average loss: 0.0033\n",
      "AUC: 0.660759493670886 , Accuracy: 0.9075144508670521, AUPRC: 0.14464778057791897\n",
      "----------\n",
      "epoch 99/400\n",
      "epoch 99 average loss: 0.0033\n",
      "----------\n",
      "epoch 100/400\n",
      "epoch 100 average loss: 0.0033\n",
      "AUC: 0.6616033755274262 , Accuracy: 0.9075144508670521, AUPRC: 0.14424305018164976\n",
      "----------\n",
      "epoch 101/400\n",
      "epoch 101 average loss: 0.0033\n",
      "----------\n",
      "epoch 102/400\n",
      "epoch 102 average loss: 0.0033\n",
      "AUC: 0.6616033755274262 , Accuracy: 0.9075144508670521, AUPRC: 0.14386174363118898\n",
      "----------\n",
      "epoch 103/400\n",
      "epoch 103 average loss: 0.0033\n",
      "----------\n",
      "epoch 104/400\n",
      "epoch 104 average loss: 0.0032\n",
      "AUC: 0.6628691983122363 , Accuracy: 0.9075144508670521, AUPRC: 0.14493846523422638\n",
      "----------\n",
      "epoch 105/400\n",
      "epoch 105 average loss: 0.0032\n",
      "----------\n",
      "epoch 106/400\n",
      "epoch 106 average loss: 0.0032\n",
      "AUC: 0.6624472573839661 , Accuracy: 0.9075144508670521, AUPRC: 0.14460244372885003\n",
      "----------\n",
      "epoch 107/400\n",
      "epoch 107 average loss: 0.0032\n",
      "----------\n",
      "epoch 108/400\n",
      "epoch 108 average loss: 0.0032\n",
      "AUC: 0.6628691983122363 , Accuracy: 0.9075144508670521, AUPRC: 0.1446548134591459\n",
      "----------\n",
      "epoch 109/400\n",
      "epoch 109 average loss: 0.0032\n",
      "----------\n",
      "epoch 110/400\n",
      "epoch 110 average loss: 0.0032\n",
      "AUC: 0.6641350210970465 , Accuracy: 0.9075144508670521, AUPRC: 0.14573200162565098\n",
      "----------\n",
      "epoch 111/400\n",
      "epoch 111 average loss: 0.0032\n",
      "----------\n",
      "epoch 112/400\n",
      "epoch 112 average loss: 0.0032\n",
      "AUC: 0.6641350210970465 , Accuracy: 0.9075144508670521, AUPRC: 0.14573200162565098\n",
      "----------\n",
      "epoch 113/400\n",
      "epoch 113 average loss: 0.0032\n",
      "----------\n",
      "epoch 114/400\n",
      "epoch 114 average loss: 0.0032\n",
      "AUC: 0.6645569620253164 , Accuracy: 0.9075144508670521, AUPRC: 0.1461856575815539\n",
      "----------\n",
      "epoch 115/400\n",
      "epoch 115 average loss: 0.0032\n",
      "----------\n",
      "epoch 116/400\n",
      "epoch 116 average loss: 0.0032\n",
      "AUC: 0.6654008438818566 , Accuracy: 0.9075144508670521, AUPRC: 0.14647685123027931\n",
      "----------\n",
      "epoch 117/400\n",
      "epoch 117 average loss: 0.0032\n",
      "----------\n",
      "epoch 118/400\n",
      "epoch 118 average loss: 0.0032\n",
      "AUC: 0.6658227848101266 , Accuracy: 0.9075144508670521, AUPRC: 0.14681298568406084\n",
      "----------\n",
      "epoch 119/400\n",
      "epoch 119 average loss: 0.0032\n",
      "----------\n",
      "epoch 120/400\n",
      "epoch 120 average loss: 0.0032\n",
      "AUC: 0.6666666666666667 , Accuracy: 0.9075144508670521, AUPRC: 0.14733352509905262\n",
      "----------\n",
      "epoch 121/400\n",
      "epoch 121 average loss: 0.0032\n",
      "----------\n",
      "epoch 122/400\n",
      "epoch 122 average loss: 0.0032\n",
      "AUC: 0.6666666666666667 , Accuracy: 0.9075144508670521, AUPRC: 0.1474622560172572\n",
      "----------\n",
      "epoch 123/400\n",
      "epoch 123 average loss: 0.0032\n",
      "----------\n",
      "epoch 124/400\n",
      "epoch 124 average loss: 0.0031\n",
      "AUC: 0.6670886075949367 , Accuracy: 0.9075144508670521, AUPRC: 0.14834143741615255\n",
      "----------\n",
      "epoch 125/400\n",
      "epoch 125 average loss: 0.0031\n",
      "----------\n",
      "epoch 126/400\n",
      "epoch 126 average loss: 0.0031\n",
      "AUC: 0.6666666666666666 , Accuracy: 0.9075144508670521, AUPRC: 0.14785834562871292\n",
      "----------\n",
      "epoch 127/400\n",
      "epoch 127 average loss: 0.0031\n",
      "----------\n",
      "epoch 128/400\n",
      "epoch 128 average loss: 0.0031\n",
      "AUC: 0.6666666666666666 , Accuracy: 0.9075144508670521, AUPRC: 0.1481208670315411\n",
      "----------\n",
      "epoch 129/400\n",
      "epoch 129 average loss: 0.0031\n",
      "----------\n",
      "epoch 130/400\n",
      "epoch 130 average loss: 0.0031\n",
      "AUC: 0.6670886075949367 , Accuracy: 0.9075144508670521, AUPRC: 0.14845688853691744\n",
      "----------\n",
      "epoch 131/400\n",
      "epoch 131 average loss: 0.0031\n",
      "----------\n",
      "epoch 132/400\n",
      "epoch 132 average loss: 0.0031\n",
      "AUC: 0.6675105485232068 , Accuracy: 0.9075144508670521, AUPRC: 0.148681355428051\n",
      "----------\n",
      "epoch 133/400\n",
      "epoch 133 average loss: 0.0031\n",
      "----------\n",
      "epoch 134/400\n",
      "epoch 134 average loss: 0.0031\n",
      "AUC: 0.6683544303797468 , Accuracy: 0.9075144508670521, AUPRC: 0.14920788881975294\n",
      "----------\n",
      "epoch 135/400\n",
      "epoch 135 average loss: 0.0031\n",
      "----------\n",
      "epoch 136/400\n",
      "epoch 136 average loss: 0.0031\n",
      "AUC: 0.6687763713080169 , Accuracy: 0.9075144508670521, AUPRC: 0.1495643950586121\n",
      "----------\n",
      "epoch 137/400\n",
      "epoch 137 average loss: 0.0031\n",
      "----------\n",
      "epoch 138/400\n",
      "epoch 138 average loss: 0.0031\n",
      "AUC: 0.6691983122362869 , Accuracy: 0.9017341040462428, AUPRC: 0.14985771285192992\n",
      "----------\n",
      "epoch 139/400\n",
      "epoch 139 average loss: 0.0031\n",
      "----------\n",
      "epoch 140/400\n",
      "epoch 140 average loss: 0.0031\n",
      "AUC: 0.6700421940928271 , Accuracy: 0.9017341040462428, AUPRC: 0.15034565515528803\n",
      "----------\n",
      "epoch 141/400\n",
      "epoch 141 average loss: 0.0031\n",
      "----------\n",
      "epoch 142/400\n",
      "epoch 142 average loss: 0.0031\n",
      "AUC: 0.670464135021097 , Accuracy: 0.9017341040462428, AUPRC: 0.150398818366346\n",
      "----------\n",
      "epoch 143/400\n",
      "epoch 143 average loss: 0.0031\n",
      "----------\n",
      "epoch 144/400\n",
      "epoch 144 average loss: 0.0030\n",
      "AUC: 0.670464135021097 , Accuracy: 0.9017341040462428, AUPRC: 0.14994672161758954\n",
      "----------\n",
      "epoch 145/400\n",
      "epoch 145 average loss: 0.0030\n",
      "----------\n",
      "epoch 146/400\n",
      "epoch 146 average loss: 0.0030\n",
      "AUC: 0.6708860759493671 , Accuracy: 0.8959537572254336, AUPRC: 0.15018861808590112\n",
      "----------\n",
      "epoch 147/400\n",
      "epoch 147 average loss: 0.0030\n",
      "----------\n",
      "epoch 148/400\n",
      "epoch 148 average loss: 0.0030\n",
      "AUC: 0.6708860759493671 , Accuracy: 0.8959537572254336, AUPRC: 0.15046856109151674\n",
      "----------\n",
      "epoch 149/400\n",
      "epoch 149 average loss: 0.0030\n",
      "----------\n",
      "epoch 150/400\n",
      "epoch 150 average loss: 0.0030\n",
      "AUC: 0.6717299578059073 , Accuracy: 0.8959537572254336, AUPRC: 0.15038400808073663\n",
      "----------\n",
      "epoch 151/400\n",
      "epoch 151 average loss: 0.0030\n",
      "----------\n",
      "epoch 152/400\n",
      "epoch 152 average loss: 0.0030\n",
      "AUC: 0.671729957805907 , Accuracy: 0.8901734104046243, AUPRC: 0.15066880999817145\n",
      "----------\n",
      "epoch 153/400\n",
      "epoch 153 average loss: 0.0030\n",
      "----------\n",
      "epoch 154/400\n",
      "epoch 154 average loss: 0.0030\n",
      "AUC: 0.671729957805907 , Accuracy: 0.8901734104046243, AUPRC: 0.15066880999817145\n",
      "----------\n",
      "epoch 155/400\n",
      "epoch 155 average loss: 0.0030\n",
      "----------\n",
      "epoch 156/400\n",
      "epoch 156 average loss: 0.0030\n",
      "AUC: 0.6738396624472573 , Accuracy: 0.8901734104046243, AUPRC: 0.15183683836019848\n",
      "----------\n",
      "epoch 157/400\n",
      "epoch 157 average loss: 0.0030\n",
      "----------\n",
      "epoch 158/400\n",
      "epoch 158 average loss: 0.0030\n",
      "AUC: 0.6742616033755274 , Accuracy: 0.8901734104046243, AUPRC: 0.15219334459905767\n",
      "----------\n",
      "epoch 159/400\n",
      "epoch 159 average loss: 0.2079\n",
      "----------\n",
      "epoch 160/400\n",
      "epoch 160 average loss: 0.5280\n",
      "AUC: 0.6725738396624472 , Accuracy: 0.9075144508670521, AUPRC: 0.17728588768661893\n",
      "----------\n",
      "epoch 161/400\n",
      "epoch 161 average loss: 0.3268\n",
      "----------\n",
      "epoch 162/400\n",
      "epoch 162 average loss: 0.0796\n",
      "AUC: 0.6350210970464135 , Accuracy: 0.8670520231213873, AUPRC: 0.13972830571838274\n",
      "----------\n",
      "epoch 163/400\n",
      "epoch 163 average loss: 0.0030\n",
      "----------\n",
      "epoch 164/400\n",
      "epoch 164 average loss: 0.0027\n",
      "AUC: 0.6345991561181435 , Accuracy: 0.8959537572254336, AUPRC: 0.14053674057631\n",
      "----------\n",
      "epoch 165/400\n",
      "epoch 165 average loss: 0.0027\n",
      "----------\n",
      "epoch 166/400\n",
      "epoch 166 average loss: 0.0027\n",
      "AUC: 0.6350210970464135 , Accuracy: 0.8959537572254336, AUPRC: 0.1406688727084421\n",
      "----------\n",
      "epoch 167/400\n",
      "epoch 167 average loss: 0.0027\n",
      "----------\n",
      "epoch 168/400\n",
      "epoch 168 average loss: 0.0027\n",
      "AUC: 0.6350210970464135 , Accuracy: 0.8959537572254336, AUPRC: 0.14047565940272166\n",
      "----------\n",
      "epoch 169/400\n",
      "epoch 169 average loss: 0.0027\n",
      "----------\n",
      "epoch 170/400\n",
      "epoch 170 average loss: 0.0027\n",
      "AUC: 0.6350210970464135 , Accuracy: 0.8959537572254336, AUPRC: 0.14035376263996724\n",
      "----------\n",
      "epoch 171/400\n",
      "epoch 171 average loss: 0.0027\n",
      "----------\n",
      "epoch 172/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172 average loss: 0.0027\n",
      "AUC: 0.6362869198312235 , Accuracy: 0.8959537572254336, AUPRC: 0.14060070934214813\n",
      "----------\n",
      "epoch 173/400\n",
      "epoch 173 average loss: 0.0027\n",
      "----------\n",
      "epoch 174/400\n",
      "epoch 174 average loss: 0.0027\n",
      "AUC: 0.6358649789029536 , Accuracy: 0.8959537572254336, AUPRC: 0.14049625646727096\n",
      "----------\n",
      "epoch 175/400\n",
      "epoch 175 average loss: 0.0026\n",
      "----------\n",
      "epoch 176/400\n",
      "epoch 176 average loss: 0.0026\n",
      "AUC: 0.6358649789029536 , Accuracy: 0.8959537572254336, AUPRC: 0.14098220462763772\n",
      "----------\n",
      "epoch 177/400\n",
      "epoch 177 average loss: 0.0026\n",
      "----------\n",
      "epoch 178/400\n",
      "epoch 178 average loss: 0.0026\n",
      "AUC: 0.6354430379746835 , Accuracy: 0.8959537572254336, AUPRC: 0.14083402645129053\n",
      "----------\n",
      "epoch 179/400\n",
      "epoch 179 average loss: 0.0026\n",
      "----------\n",
      "epoch 180/400\n",
      "epoch 180 average loss: 0.0026\n",
      "AUC: 0.6362869198312237 , Accuracy: 0.8959537572254336, AUPRC: 0.1413557516396824\n",
      "----------\n",
      "epoch 181/400\n",
      "epoch 181 average loss: 0.0026\n",
      "----------\n",
      "epoch 182/400\n",
      "epoch 182 average loss: 0.0026\n",
      "AUC: 0.6371308016877637 , Accuracy: 0.8959537572254336, AUPRC: 0.14265489693882769\n",
      "----------\n",
      "epoch 183/400\n",
      "epoch 183 average loss: 0.0026\n",
      "----------\n",
      "epoch 184/400\n",
      "epoch 184 average loss: 0.0026\n",
      "AUC: 0.6375527426160338 , Accuracy: 0.8959537572254336, AUPRC: 0.1427906491293744\n",
      "----------\n",
      "epoch 185/400\n",
      "epoch 185 average loss: 0.0026\n",
      "----------\n",
      "epoch 186/400\n",
      "epoch 186 average loss: 0.0026\n",
      "AUC: 0.6383966244725738 , Accuracy: 0.8959537572254336, AUPRC: 0.14300724451699592\n",
      "----------\n",
      "epoch 187/400\n",
      "epoch 187 average loss: 0.0026\n",
      "----------\n",
      "epoch 188/400\n",
      "epoch 188 average loss: 0.0026\n",
      "AUC: 0.6383966244725738 , Accuracy: 0.8959537572254336, AUPRC: 0.14300724451699592\n",
      "----------\n",
      "epoch 189/400\n",
      "epoch 189 average loss: 0.0026\n",
      "----------\n",
      "epoch 190/400\n",
      "epoch 190 average loss: 0.0025\n",
      "AUC: 0.6383966244725738 , Accuracy: 0.8959537572254336, AUPRC: 0.14300724451699592\n",
      "----------\n",
      "epoch 191/400\n",
      "epoch 191 average loss: 0.0025\n",
      "----------\n",
      "epoch 192/400\n",
      "epoch 192 average loss: 0.0025\n",
      "AUC: 0.6379746835443038 , Accuracy: 0.8959537572254336, AUPRC: 0.14287155930668388\n",
      "----------\n",
      "epoch 193/400\n",
      "epoch 193 average loss: 0.0025\n",
      "----------\n",
      "epoch 194/400\n",
      "epoch 194 average loss: 0.0025\n",
      "AUC: 0.6388185654008438 , Accuracy: 0.8959537572254336, AUPRC: 0.14315453570387981\n",
      "----------\n",
      "epoch 195/400\n",
      "epoch 195 average loss: 0.0025\n",
      "----------\n",
      "epoch 196/400\n",
      "epoch 196 average loss: 0.0025\n",
      "AUC: 0.6392405063291139 , Accuracy: 0.8959537572254336, AUPRC: 0.14329256192886258\n",
      "----------\n",
      "epoch 197/400\n",
      "epoch 197 average loss: 0.0025\n",
      "----------\n",
      "epoch 198/400\n",
      "epoch 198 average loss: 0.0025\n",
      "AUC: 0.6392405063291139 , Accuracy: 0.8959537572254336, AUPRC: 0.14329256192886258\n",
      "----------\n",
      "epoch 199/400\n",
      "epoch 199 average loss: 0.0025\n",
      "----------\n",
      "epoch 200/400\n",
      "epoch 200 average loss: 0.0025\n",
      "AUC: 0.6388185654008438 , Accuracy: 0.8959537572254336, AUPRC: 0.1432101047035482\n",
      "----------\n",
      "epoch 201/400\n",
      "epoch 201 average loss: 0.0025\n",
      "----------\n",
      "epoch 202/400\n",
      "epoch 202 average loss: 0.0025\n",
      "AUC: 0.6392405063291139 , Accuracy: 0.8959537572254336, AUPRC: 0.1433576566820861\n",
      "----------\n",
      "epoch 203/400\n",
      "epoch 203 average loss: 0.0025\n",
      "----------\n",
      "epoch 204/400\n",
      "epoch 204 average loss: 0.0025\n",
      "AUC: 0.6392405063291139 , Accuracy: 0.8959537572254336, AUPRC: 0.1433576566820861\n",
      "----------\n",
      "epoch 205/400\n",
      "epoch 205 average loss: 0.0024\n",
      "----------\n",
      "epoch 206/400\n",
      "epoch 206 average loss: 0.0024\n",
      "AUC: 0.6392405063291139 , Accuracy: 0.8959537572254336, AUPRC: 0.1433576566820861\n",
      "----------\n",
      "epoch 207/400\n",
      "epoch 207 average loss: 0.0024\n",
      "----------\n",
      "epoch 208/400\n",
      "epoch 208 average loss: 0.0024\n",
      "AUC: 0.6388185654008438 , Accuracy: 0.8959537572254336, AUPRC: 0.14291673957450232\n",
      "----------\n",
      "epoch 209/400\n",
      "epoch 209 average loss: 0.0024\n",
      "----------\n",
      "epoch 210/400\n",
      "epoch 210 average loss: 0.0024\n",
      "AUC: 0.639240506329114 , Accuracy: 0.8959537572254336, AUPRC: 0.14295963961740238\n",
      "----------\n",
      "epoch 211/400\n",
      "epoch 211 average loss: 0.0024\n",
      "----------\n",
      "epoch 212/400\n",
      "epoch 212 average loss: 0.0024\n",
      "AUC: 0.6400843881856539 , Accuracy: 0.8959537572254336, AUPRC: 0.14305617725779965\n",
      "----------\n",
      "epoch 213/400\n",
      "epoch 213 average loss: 0.0024\n",
      "----------\n",
      "epoch 214/400\n",
      "epoch 214 average loss: 0.0024\n",
      "AUC: 0.640084388185654 , Accuracy: 0.8959537572254336, AUPRC: 0.1432928294944519\n",
      "----------\n",
      "epoch 215/400\n",
      "epoch 215 average loss: 0.0024\n",
      "----------\n",
      "epoch 216/400\n",
      "epoch 216 average loss: 0.0024\n",
      "AUC: 0.639662447257384 , Accuracy: 0.8959537572254336, AUPRC: 0.14301630224444506\n",
      "----------\n",
      "epoch 217/400\n",
      "epoch 217 average loss: 0.0024\n",
      "----------\n",
      "epoch 218/400\n",
      "epoch 218 average loss: 0.0024\n",
      "AUC: 0.639240506329114 , Accuracy: 0.8901734104046243, AUPRC: 0.14257185780000062\n",
      "----------\n",
      "epoch 219/400\n",
      "epoch 219 average loss: 0.0024\n",
      "----------\n",
      "epoch 220/400\n",
      "epoch 220 average loss: 0.0024\n",
      "AUC: 0.639240506329114 , Accuracy: 0.8901734104046243, AUPRC: 0.14257185780000062\n",
      "----------\n",
      "epoch 221/400\n",
      "epoch 221 average loss: 0.0023\n",
      "----------\n",
      "epoch 222/400\n",
      "epoch 222 average loss: 0.0023\n",
      "AUC: 0.639240506329114 , Accuracy: 0.8901734104046243, AUPRC: 0.14257185780000062\n",
      "----------\n",
      "epoch 223/400\n",
      "epoch 223 average loss: 0.0023\n",
      "----------\n",
      "epoch 224/400\n",
      "epoch 224 average loss: 0.0023\n",
      "AUC: 0.639240506329114 , Accuracy: 0.8901734104046243, AUPRC: 0.14185924276513495\n",
      "----------\n",
      "epoch 225/400\n",
      "epoch 225 average loss: 0.0023\n",
      "----------\n",
      "epoch 226/400\n",
      "epoch 226 average loss: 0.0023\n",
      "AUC: 0.6388185654008439 , Accuracy: 0.8901734104046243, AUPRC: 0.14144898635487854\n",
      "----------\n",
      "epoch 227/400\n",
      "epoch 227 average loss: 0.0023\n",
      "----------\n",
      "epoch 228/400\n",
      "epoch 228 average loss: 0.0023\n",
      "AUC: 0.6388185654008439 , Accuracy: 0.8901734104046243, AUPRC: 0.14144898635487854\n",
      "----------\n",
      "epoch 229/400\n",
      "epoch 229 average loss: 0.0023\n",
      "----------\n",
      "epoch 230/400\n",
      "epoch 230 average loss: 0.0023\n",
      "AUC: 0.6383966244725738 , Accuracy: 0.8901734104046243, AUPRC: 0.14137133153057257\n",
      "----------\n",
      "epoch 231/400\n",
      "epoch 231 average loss: 0.0023\n",
      "----------\n",
      "epoch 232/400\n",
      "epoch 232 average loss: 0.0023\n",
      "AUC: 0.6383966244725738 , Accuracy: 0.8901734104046243, AUPRC: 0.14143086977724484\n",
      "----------\n",
      "epoch 233/400\n",
      "epoch 233 average loss: 0.0023\n",
      "----------\n",
      "epoch 234/400\n",
      "epoch 234 average loss: 0.0023\n",
      "AUC: 0.6388185654008439 , Accuracy: 0.8901734104046243, AUPRC: 0.14166656001293507\n",
      "----------\n",
      "epoch 235/400\n",
      "epoch 235 average loss: 0.0023\n",
      "----------\n",
      "epoch 236/400\n",
      "epoch 236 average loss: 0.0023\n",
      "AUC: 0.639662447257384 , Accuracy: 0.8901734104046243, AUPRC: 0.14217161051798557\n",
      "----------\n",
      "epoch 237/400\n",
      "epoch 237 average loss: 0.0022\n",
      "----------\n",
      "epoch 238/400\n",
      "epoch 238 average loss: 0.0022\n",
      "AUC: 0.6383966244725738 , Accuracy: 0.8901734104046243, AUPRC: 0.14126181777873342\n",
      "----------\n",
      "epoch 239/400\n",
      "epoch 239 average loss: 0.0022\n",
      "----------\n",
      "epoch 240/400\n",
      "epoch 240 average loss: 0.0022\n",
      "AUC: 0.6379746835443039 , Accuracy: 0.8901734104046243, AUPRC: 0.14118850267241118\n",
      "----------\n",
      "epoch 241/400\n",
      "epoch 241 average loss: 0.0022\n",
      "----------\n",
      "epoch 242/400\n",
      "epoch 242 average loss: 0.0022\n",
      "AUC: 0.6379746835443039 , Accuracy: 0.8901734104046243, AUPRC: 0.14110136703267018\n",
      "----------\n",
      "epoch 243/400\n",
      "epoch 243 average loss: 0.0022\n",
      "----------\n",
      "epoch 244/400\n",
      "epoch 244 average loss: 0.0022\n",
      "AUC: 0.6383966244725738 , Accuracy: 0.8901734104046243, AUPRC: 0.14134805220072444\n",
      "----------\n",
      "epoch 245/400\n",
      "epoch 245 average loss: 0.0022\n",
      "----------\n",
      "epoch 246/400\n",
      "epoch 246 average loss: 0.0022\n",
      "AUC: 0.639662447257384 , Accuracy: 0.8901734104046243, AUPRC: 0.14186896055593515\n",
      "----------\n",
      "epoch 247/400\n",
      "epoch 247 average loss: 0.0022\n",
      "----------\n",
      "epoch 248/400\n",
      "epoch 248 average loss: 0.0022\n",
      "AUC: 0.639240506329114 , Accuracy: 0.8901734104046243, AUPRC: 0.14199624056899557\n",
      "----------\n",
      "epoch 249/400\n",
      "epoch 249 average loss: 0.0022\n",
      "----------\n",
      "epoch 250/400\n",
      "epoch 250 average loss: 0.0022\n",
      "AUC: 0.6388185654008438 , Accuracy: 0.8901734104046243, AUPRC: 0.14120942468100722\n",
      "----------\n",
      "epoch 251/400\n",
      "epoch 251 average loss: 0.0022\n",
      "----------\n",
      "epoch 252/400\n",
      "epoch 252 average loss: 0.0021\n",
      "AUC: 0.6388185654008439 , Accuracy: 0.8901734104046243, AUPRC: 0.14102918468187975\n",
      "----------\n",
      "epoch 253/400\n",
      "epoch 253 average loss: 0.0021\n",
      "----------\n",
      "epoch 254/400\n",
      "epoch 254 average loss: 0.0021\n",
      "AUC: 0.639662447257384 , Accuracy: 0.8901734104046243, AUPRC: 0.14136526922869652\n",
      "----------\n",
      "epoch 255/400\n",
      "epoch 255 average loss: 0.0021\n",
      "----------\n",
      "epoch 256/400\n",
      "epoch 256 average loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.640506329113924 , Accuracy: 0.8901734104046243, AUPRC: 0.14202242763294795\n",
      "----------\n",
      "epoch 257/400\n",
      "epoch 257 average loss: 0.0021\n",
      "----------\n",
      "epoch 258/400\n",
      "epoch 258 average loss: 0.0021\n",
      "AUC: 0.6421940928270042 , Accuracy: 0.8901734104046243, AUPRC: 0.1434845501899361\n",
      "----------\n",
      "epoch 259/400\n",
      "epoch 259 average loss: 0.0021\n",
      "----------\n",
      "epoch 260/400\n",
      "epoch 260 average loss: 0.0021\n",
      "AUC: 0.6417721518987342 , Accuracy: 0.8901734104046243, AUPRC: 0.1428410700311982\n",
      "----------\n",
      "epoch 261/400\n",
      "epoch 261 average loss: 0.0021\n",
      "----------\n",
      "epoch 262/400\n",
      "epoch 262 average loss: 0.0021\n",
      "AUC: 0.6421940928270042 , Accuracy: 0.8901734104046243, AUPRC: 0.14305542400070898\n",
      "----------\n",
      "epoch 263/400\n",
      "epoch 263 average loss: 0.0021\n",
      "----------\n",
      "epoch 264/400\n",
      "epoch 264 average loss: 0.0021\n",
      "AUC: 0.6443037974683544 , Accuracy: 0.8901734104046243, AUPRC: 0.1443636636082931\n",
      "----------\n",
      "epoch 265/400\n",
      "epoch 265 average loss: 0.0021\n",
      "----------\n",
      "epoch 266/400\n",
      "epoch 266 average loss: 0.0021\n",
      "AUC: 0.6443037974683544 , Accuracy: 0.884393063583815, AUPRC: 0.14463721092631673\n",
      "----------\n",
      "epoch 267/400\n",
      "epoch 267 average loss: 0.0020\n",
      "----------\n",
      "epoch 268/400\n",
      "epoch 268 average loss: 0.0020\n",
      "AUC: 0.6447257383966245 , Accuracy: 0.884393063583815, AUPRC: 0.14471750707220657\n",
      "----------\n",
      "epoch 269/400\n",
      "epoch 269 average loss: 0.0020\n",
      "----------\n",
      "epoch 270/400\n",
      "epoch 270 average loss: 0.0020\n",
      "AUC: 0.6451476793248946 , Accuracy: 0.884393063583815, AUPRC: 0.14516276919380694\n",
      "----------\n",
      "epoch 271/400\n",
      "epoch 271 average loss: 0.0020\n",
      "----------\n",
      "epoch 272/400\n",
      "epoch 272 average loss: 0.0020\n",
      "AUC: 0.6468354430379747 , Accuracy: 0.884393063583815, AUPRC: 0.14573851591171447\n",
      "----------\n",
      "epoch 273/400\n",
      "epoch 273 average loss: 0.0020\n",
      "----------\n",
      "epoch 274/400\n",
      "epoch 274 average loss: 0.0020\n",
      "AUC: 0.6476793248945149 , Accuracy: 0.884393063583815, AUPRC: 0.14647771665091522\n",
      "----------\n",
      "epoch 275/400\n",
      "epoch 275 average loss: 0.0020\n",
      "----------\n",
      "epoch 276/400\n",
      "epoch 276 average loss: 0.0020\n",
      "AUC: 0.6485232067510549 , Accuracy: 0.884393063583815, AUPRC: 0.1460455920564896\n",
      "----------\n",
      "epoch 277/400\n",
      "epoch 277 average loss: 0.0020\n",
      "----------\n",
      "epoch 278/400\n",
      "epoch 278 average loss: 0.0020\n",
      "AUC: 0.6489451476793249 , Accuracy: 0.884393063583815, AUPRC: 0.14672757672948294\n",
      "----------\n",
      "epoch 279/400\n",
      "epoch 279 average loss: 0.0020\n",
      "----------\n",
      "epoch 280/400\n",
      "epoch 280 average loss: 0.0020\n",
      "AUC: 0.6502109704641351 , Accuracy: 0.884393063583815, AUPRC: 0.14789762300869835\n",
      "----------\n",
      "epoch 281/400\n",
      "epoch 281 average loss: 0.0019\n",
      "----------\n",
      "epoch 282/400\n",
      "epoch 282 average loss: 0.0019\n",
      "AUC: 0.6518987341772152 , Accuracy: 0.884393063583815, AUPRC: 0.14926583215060468\n",
      "----------\n",
      "epoch 283/400\n",
      "epoch 283 average loss: 0.0019\n",
      "----------\n",
      "epoch 284/400\n",
      "epoch 284 average loss: 0.0019\n",
      "AUC: 0.6531645569620254 , Accuracy: 0.884393063583815, AUPRC: 0.14911512664299129\n",
      "----------\n",
      "epoch 285/400\n",
      "epoch 285 average loss: 0.0019\n",
      "----------\n",
      "epoch 286/400\n",
      "epoch 286 average loss: 0.0019\n",
      "AUC: 0.6544303797468355 , Accuracy: 0.884393063583815, AUPRC: 0.1498950938022688\n",
      "----------\n",
      "epoch 287/400\n",
      "epoch 287 average loss: 0.0019\n",
      "----------\n",
      "epoch 288/400\n",
      "epoch 288 average loss: 0.0019\n",
      "AUC: 0.6548523206751056 , Accuracy: 0.884393063583815, AUPRC: 0.1490538682083562\n",
      "----------\n",
      "epoch 289/400\n",
      "epoch 289 average loss: 0.0019\n",
      "----------\n",
      "epoch 290/400\n",
      "epoch 290 average loss: 0.0019\n",
      "AUC: 0.6556962025316456 , Accuracy: 0.884393063583815, AUPRC: 0.14926325701529675\n",
      "----------\n",
      "epoch 291/400\n",
      "epoch 291 average loss: 0.0019\n",
      "----------\n",
      "epoch 292/400\n",
      "epoch 292 average loss: 0.0019\n",
      "AUC: 0.6565400843881857 , Accuracy: 0.884393063583815, AUPRC: 0.15043828478346177\n",
      "----------\n",
      "epoch 293/400\n",
      "epoch 293 average loss: 0.0019\n",
      "----------\n",
      "epoch 294/400\n",
      "epoch 294 average loss: 0.0019\n",
      "AUC: 0.6573839662447257 , Accuracy: 0.884393063583815, AUPRC: 0.15056719283421166\n",
      "----------\n",
      "epoch 295/400\n",
      "epoch 295 average loss: 0.0018\n",
      "----------\n",
      "epoch 296/400\n",
      "epoch 296 average loss: 0.1053\n",
      "AUC: 0.6683544303797468 , Accuracy: 0.5086705202312138, AUPRC: 0.1453319164161252\n",
      "----------\n",
      "epoch 297/400\n",
      "epoch 297 average loss: 0.2200\n",
      "----------\n",
      "epoch 298/400\n",
      "epoch 298 average loss: 0.0556\n",
      "AUC: 0.6518987341772151 , Accuracy: 0.9132947976878613, AUPRC: 0.14324034217307063\n",
      "----------\n",
      "epoch 299/400\n",
      "epoch 299 average loss: 0.2331\n",
      "----------\n",
      "epoch 300/400\n",
      "epoch 300 average loss: 0.0019\n",
      "AUC: 0.6029535864978903 , Accuracy: 0.8901734104046243, AUPRC: 0.14248747403787218\n",
      "----------\n",
      "epoch 301/400\n",
      "epoch 301 average loss: 0.0038\n",
      "----------\n",
      "epoch 302/400\n",
      "epoch 302 average loss: 0.0018\n",
      "AUC: 0.619409282700422 , Accuracy: 0.8901734104046243, AUPRC: 0.17469845795123273\n",
      "----------\n",
      "epoch 303/400\n",
      "epoch 303 average loss: 0.0018\n",
      "----------\n",
      "epoch 304/400\n",
      "epoch 304 average loss: 0.0018\n",
      "AUC: 0.619831223628692 , Accuracy: 0.8901734104046243, AUPRC: 0.17498295297256988\n",
      "----------\n",
      "epoch 305/400\n",
      "epoch 305 average loss: 0.0018\n",
      "----------\n",
      "epoch 306/400\n",
      "epoch 306 average loss: 0.0018\n",
      "AUC: 0.6189873417721519 , Accuracy: 0.8901734104046243, AUPRC: 0.1748354297083115\n",
      "----------\n",
      "epoch 307/400\n",
      "epoch 307 average loss: 0.0018\n",
      "----------\n",
      "epoch 308/400\n",
      "epoch 308 average loss: 0.0018\n",
      "AUC: 0.6189873417721519 , Accuracy: 0.8901734104046243, AUPRC: 0.1748354297083115\n",
      "----------\n",
      "epoch 309/400\n",
      "epoch 309 average loss: 0.0018\n",
      "----------\n",
      "epoch 310/400\n",
      "epoch 310 average loss: 0.0018\n",
      "AUC: 0.6181434599156118 , Accuracy: 0.8901734104046243, AUPRC: 0.17460776541368112\n",
      "----------\n",
      "epoch 311/400\n",
      "epoch 311 average loss: 0.0018\n",
      "----------\n",
      "epoch 312/400\n",
      "epoch 312 average loss: 0.0018\n",
      "AUC: 0.6185654008438818 , Accuracy: 0.8901734104046243, AUPRC: 0.17471595539528884\n",
      "----------\n",
      "epoch 313/400\n",
      "epoch 313 average loss: 0.0018\n",
      "----------\n",
      "epoch 314/400\n",
      "epoch 314 average loss: 0.0018\n",
      "AUC: 0.6189873417721519 , Accuracy: 0.8901734104046243, AUPRC: 0.17492030068980158\n",
      "----------\n",
      "epoch 315/400\n",
      "epoch 315 average loss: 0.0018\n",
      "----------\n",
      "epoch 316/400\n",
      "epoch 316 average loss: 0.0018\n",
      "AUC: 0.6189873417721519 , Accuracy: 0.8901734104046243, AUPRC: 0.17492030068980158\n",
      "----------\n",
      "epoch 317/400\n",
      "epoch 317 average loss: 0.0018\n",
      "----------\n",
      "epoch 318/400\n",
      "epoch 318 average loss: 0.0018\n",
      "AUC: 0.619409282700422 , Accuracy: 0.8901734104046243, AUPRC: 0.17495840837122137\n",
      "----------\n",
      "epoch 319/400\n",
      "epoch 319 average loss: 0.0018\n",
      "----------\n",
      "epoch 320/400\n",
      "epoch 320 average loss: 0.0018\n",
      "AUC: 0.6194092827004221 , Accuracy: 0.8901734104046243, AUPRC: 0.17500045173004727\n",
      "----------\n",
      "epoch 321/400\n",
      "epoch 321 average loss: 0.0017\n",
      "----------\n",
      "epoch 322/400\n",
      "epoch 322 average loss: 0.0017\n",
      "AUC: 0.6194092827004221 , Accuracy: 0.8901734104046243, AUPRC: 0.17500045173004727\n",
      "----------\n",
      "epoch 323/400\n",
      "epoch 323 average loss: 0.0017\n",
      "----------\n",
      "epoch 324/400\n",
      "epoch 324 average loss: 0.0017\n",
      "AUC: 0.618987341772152 , Accuracy: 0.8901734104046243, AUPRC: 0.17490243872104788\n",
      "----------\n",
      "epoch 325/400\n",
      "epoch 325 average loss: 0.0017\n",
      "----------\n",
      "epoch 326/400\n",
      "epoch 326 average loss: 0.0017\n",
      "AUC: 0.619409282700422 , Accuracy: 0.8901734104046243, AUPRC: 0.17468528622796597\n",
      "----------\n",
      "epoch 327/400\n",
      "epoch 327 average loss: 0.0017\n",
      "----------\n",
      "epoch 328/400\n",
      "epoch 328 average loss: 0.0017\n",
      "AUC: 0.619409282700422 , Accuracy: 0.8901734104046243, AUPRC: 0.17468528622796597\n",
      "----------\n",
      "epoch 329/400\n",
      "epoch 329 average loss: 0.0017\n",
      "----------\n",
      "epoch 330/400\n",
      "epoch 330 average loss: 0.0017\n",
      "AUC: 0.6198312236286921 , Accuracy: 0.8901734104046243, AUPRC: 0.1748175613602411\n",
      "----------\n",
      "epoch 331/400\n",
      "epoch 331 average loss: 0.0017\n",
      "----------\n",
      "epoch 332/400\n",
      "epoch 332 average loss: 0.0017\n",
      "AUC: 0.6198312236286921 , Accuracy: 0.8901734104046243, AUPRC: 0.1748175613602411\n",
      "----------\n",
      "epoch 333/400\n",
      "epoch 333 average loss: 0.0017\n",
      "----------\n",
      "epoch 334/400\n",
      "epoch 334 average loss: 0.0017\n",
      "AUC: 0.619831223628692 , Accuracy: 0.8901734104046243, AUPRC: 0.17486600668885885\n",
      "----------\n",
      "epoch 335/400\n",
      "epoch 335 average loss: 0.0017\n",
      "----------\n",
      "epoch 336/400\n",
      "epoch 336 average loss: 0.0017\n",
      "AUC: 0.6206751054852321 , Accuracy: 0.8901734104046243, AUPRC: 0.17518111682950643\n",
      "----------\n",
      "epoch 337/400\n",
      "epoch 337 average loss: 0.0017\n",
      "----------\n",
      "epoch 338/400\n",
      "epoch 338 average loss: 0.0017\n",
      "AUC: 0.6206751054852321 , Accuracy: 0.8901734104046243, AUPRC: 0.17518111682950643\n",
      "----------\n",
      "epoch 339/400\n",
      "epoch 339 average loss: 0.0017\n",
      "----------\n",
      "epoch 340/400\n",
      "epoch 340 average loss: 0.0017\n",
      "AUC: 0.6206751054852321 , Accuracy: 0.8901734104046243, AUPRC: 0.17518111682950643\n",
      "----------\n",
      "epoch 341/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 341 average loss: 0.0016\n",
      "----------\n",
      "epoch 342/400\n",
      "epoch 342 average loss: 0.0016\n",
      "AUC: 0.6210970464135022 , Accuracy: 0.8901734104046243, AUPRC: 0.17529807589383392\n",
      "----------\n",
      "epoch 343/400\n",
      "epoch 343 average loss: 0.0016\n",
      "----------\n",
      "epoch 344/400\n",
      "epoch 344 average loss: 0.0016\n",
      "AUC: 0.6210970464135022 , Accuracy: 0.8901734104046243, AUPRC: 0.17529807589383392\n",
      "----------\n",
      "epoch 345/400\n",
      "epoch 345 average loss: 0.0016\n",
      "----------\n",
      "epoch 346/400\n",
      "epoch 346 average loss: 0.0016\n",
      "AUC: 0.6210970464135023 , Accuracy: 0.8901734104046243, AUPRC: 0.17556379422418253\n",
      "----------\n",
      "epoch 347/400\n",
      "epoch 347 average loss: 0.0016\n",
      "----------\n",
      "epoch 348/400\n",
      "epoch 348 average loss: 0.0016\n",
      "AUC: 0.6223628691983124 , Accuracy: 0.8901734104046243, AUPRC: 0.17597315094932872\n",
      "----------\n",
      "epoch 349/400\n",
      "epoch 349 average loss: 0.0016\n",
      "----------\n",
      "epoch 350/400\n",
      "epoch 350 average loss: 0.0016\n",
      "AUC: 0.6232067510548523 , Accuracy: 0.8901734104046243, AUPRC: 0.1762598893005832\n",
      "----------\n",
      "epoch 351/400\n",
      "epoch 351 average loss: 0.0016\n",
      "----------\n",
      "epoch 352/400\n",
      "epoch 352 average loss: 0.0016\n",
      "AUC: 0.6240506329113924 , Accuracy: 0.8901734104046243, AUPRC: 0.17644914782773127\n",
      "----------\n",
      "epoch 353/400\n",
      "epoch 353 average loss: 0.0016\n",
      "----------\n",
      "epoch 354/400\n",
      "epoch 354 average loss: 0.0016\n",
      "AUC: 0.6244725738396625 , Accuracy: 0.8901734104046243, AUPRC: 0.17648824851199324\n",
      "----------\n",
      "epoch 355/400\n",
      "epoch 355 average loss: 0.0016\n",
      "----------\n",
      "epoch 356/400\n",
      "epoch 356 average loss: 0.0016\n",
      "AUC: 0.6253164556962025 , Accuracy: 0.8901734104046243, AUPRC: 0.17679030161865433\n",
      "----------\n",
      "epoch 357/400\n",
      "epoch 357 average loss: 0.0016\n",
      "----------\n",
      "epoch 358/400\n",
      "epoch 358 average loss: 0.0016\n",
      "AUC: 0.6257383966244726 , Accuracy: 0.8901734104046243, AUPRC: 0.1767825047567032\n",
      "----------\n",
      "epoch 359/400\n",
      "epoch 359 average loss: 0.0016\n",
      "----------\n",
      "epoch 360/400\n",
      "epoch 360 average loss: 0.0015\n",
      "AUC: 0.6257383966244726 , Accuracy: 0.8901734104046243, AUPRC: 0.1767825047567032\n",
      "----------\n",
      "epoch 361/400\n",
      "epoch 361 average loss: 0.0015\n",
      "----------\n",
      "epoch 362/400\n",
      "epoch 362 average loss: 0.0015\n",
      "AUC: 0.6257383966244726 , Accuracy: 0.8901734104046243, AUPRC: 0.176597998402842\n",
      "----------\n",
      "epoch 363/400\n",
      "epoch 363 average loss: 0.0015\n",
      "----------\n",
      "epoch 364/400\n",
      "epoch 364 average loss: 0.0015\n",
      "AUC: 0.6270042194092827 , Accuracy: 0.8901734104046243, AUPRC: 0.17698430574286936\n",
      "----------\n",
      "epoch 365/400\n",
      "epoch 365 average loss: 0.0015\n",
      "----------\n",
      "epoch 366/400\n",
      "epoch 366 average loss: 0.0015\n",
      "AUC: 0.6278481012658228 , Accuracy: 0.8901734104046243, AUPRC: 0.17739229464838746\n",
      "----------\n",
      "epoch 367/400\n",
      "epoch 367 average loss: 0.0015\n",
      "----------\n",
      "epoch 368/400\n",
      "epoch 368 average loss: 0.0015\n",
      "AUC: 0.6278481012658228 , Accuracy: 0.8901734104046243, AUPRC: 0.17739229464838746\n",
      "----------\n",
      "epoch 369/400\n",
      "epoch 369 average loss: 0.0015\n",
      "----------\n",
      "epoch 370/400\n",
      "epoch 370 average loss: 0.0015\n",
      "AUC: 0.6278481012658228 , Accuracy: 0.8901734104046243, AUPRC: 0.17750843624942841\n",
      "----------\n",
      "epoch 371/400\n",
      "epoch 371 average loss: 0.0015\n",
      "----------\n",
      "epoch 372/400\n",
      "epoch 372 average loss: 0.0015\n",
      "AUC: 0.6286919831223629 , Accuracy: 0.8901734104046243, AUPRC: 0.17777298651397866\n",
      "----------\n",
      "epoch 373/400\n",
      "epoch 373 average loss: 0.0015\n",
      "----------\n",
      "epoch 374/400\n",
      "epoch 374 average loss: 0.0015\n",
      "AUC: 0.6286919831223629 , Accuracy: 0.8901734104046243, AUPRC: 0.1774707451201215\n",
      "----------\n",
      "epoch 375/400\n",
      "epoch 375 average loss: 0.0015\n",
      "----------\n",
      "epoch 376/400\n",
      "epoch 376 average loss: 0.0015\n",
      "AUC: 0.6303797468354431 , Accuracy: 0.8901734104046243, AUPRC: 0.17813252487994047\n",
      "----------\n",
      "epoch 377/400\n",
      "epoch 377 average loss: 0.0015\n",
      "----------\n",
      "epoch 378/400\n",
      "epoch 378 average loss: 0.0015\n",
      "AUC: 0.6312236286919832 , Accuracy: 0.8901734104046243, AUPRC: 0.17838718810896198\n",
      "----------\n",
      "epoch 379/400\n",
      "epoch 379 average loss: 0.0014\n",
      "----------\n",
      "epoch 380/400\n",
      "epoch 380 average loss: 0.0014\n",
      "AUC: 0.6320675105485232 , Accuracy: 0.8901734104046243, AUPRC: 0.17879245659933687\n",
      "----------\n",
      "epoch 381/400\n",
      "epoch 381 average loss: 0.0014\n",
      "----------\n",
      "epoch 382/400\n",
      "epoch 382 average loss: 0.0014\n",
      "AUC: 0.6329113924050633 , Accuracy: 0.8901734104046243, AUPRC: 0.1790484391336536\n",
      "----------\n",
      "epoch 383/400\n",
      "epoch 383 average loss: 0.0014\n",
      "----------\n",
      "epoch 384/400\n",
      "epoch 384 average loss: 0.0014\n",
      "AUC: 0.6324894514767933 , Accuracy: 0.8901734104046243, AUPRC: 0.17884504340688115\n",
      "----------\n",
      "epoch 385/400\n",
      "epoch 385 average loss: 0.0014\n",
      "----------\n",
      "epoch 386/400\n",
      "epoch 386 average loss: 0.0014\n",
      "AUC: 0.6329113924050633 , Accuracy: 0.8901734104046243, AUPRC: 0.17907048624101965\n",
      "----------\n",
      "epoch 387/400\n",
      "epoch 387 average loss: 0.0014\n",
      "----------\n",
      "epoch 388/400\n",
      "epoch 388 average loss: 0.0014\n",
      "AUC: 0.6329113924050633 , Accuracy: 0.8901734104046243, AUPRC: 0.17897234109156698\n",
      "----------\n",
      "epoch 389/400\n",
      "epoch 389 average loss: 0.0014\n",
      "----------\n",
      "epoch 390/400\n",
      "epoch 390 average loss: 0.0014\n",
      "AUC: 0.6329113924050633 , Accuracy: 0.8901734104046243, AUPRC: 0.17897234109156698\n",
      "----------\n",
      "epoch 391/400\n",
      "epoch 391 average loss: 0.0014\n",
      "----------\n",
      "epoch 392/400\n",
      "epoch 392 average loss: 0.0014\n",
      "AUC: 0.6345991561181434 , Accuracy: 0.8901734104046243, AUPRC: 0.17655227243224544\n",
      "----------\n",
      "epoch 393/400\n",
      "epoch 393 average loss: 0.0014\n",
      "----------\n",
      "epoch 394/400\n",
      "epoch 394 average loss: 0.0014\n",
      "AUC: 0.6337552742616034 , Accuracy: 0.8901734104046243, AUPRC: 0.17123574685256196\n",
      "----------\n",
      "epoch 395/400\n",
      "epoch 395 average loss: 0.0014\n",
      "----------\n",
      "epoch 396/400\n",
      "epoch 396 average loss: 0.0014\n",
      "AUC: 0.6354430379746836 , Accuracy: 0.8901734104046243, AUPRC: 0.17217212666420428\n",
      "----------\n",
      "epoch 397/400\n",
      "epoch 397 average loss: 0.0013\n",
      "----------\n",
      "epoch 398/400\n",
      "epoch 398 average loss: 0.0013\n",
      "AUC: 0.6362869198312237 , Accuracy: 0.8901734104046243, AUPRC: 0.17236773269873648\n",
      "----------\n",
      "epoch 399/400\n",
      "epoch 399 average loss: 0.0013\n",
      "----------\n",
      "epoch 400/400\n",
      "epoch 400 average loss: 0.0013\n",
      "AUC: 0.6350210970464135 , Accuracy: 0.8901734104046243, AUPRC: 0.16805735059018923\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_metric_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-40998bfeb3c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC: {} , Accuracy: {}, AUPRC: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauprc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_metric_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ImageDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate, Resize, ScaleIntensity, EnsureType\n",
    "\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((256,256,44)), RandRotate(range_x=0.02, range_y=0.02, range_z=0.02, prob=0.5), EnsureType()])\n",
    "val_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((256,256,44)), EnsureType()])\n",
    "\n",
    "#### ======================================= T1 pre ===============================================\n",
    "# Define image dataset, data loader\n",
    "check_ds_T1_pre = ImageDataset(image_files=images_T1_pre_train, labels=labels_train, transform=train_transforms)\n",
    "check_loader_T1_pre = DataLoader(check_ds_T1_pre, batch_size=10, num_workers=2)# , pin_memory=torch.cuda.is_available())\n",
    "# create a training data loader\n",
    "train_ds_T1_pre = ImageDataset(image_files=images_T1_pre_train, labels=labels_train, transform=train_transforms)\n",
    "train_loader_T1_pre = DataLoader(train_ds_T1_pre, batch_size=10, shuffle=False, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "#create a validation data loader\n",
    "val_ds_T1_pre = ImageDataset(image_files=images_T1_pre_test, labels=labels_test, transform=val_transforms)\n",
    "val_loader_T1_pre = DataLoader(val_ds_T1_pre, batch_size=10, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "device = torch.device(14 if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss(weight=class_weights.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "\n",
    "triplet_loss = \\\n",
    "    nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance(), margin=1.5)\n",
    "\n",
    "\n",
    "\n",
    "# start a typical PyTorch training\n",
    "EPOCH = 400\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "best_AUC=0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{EPOCH}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    step = 0\n",
    "    total = 0\n",
    "    \n",
    "    iter_T1_pre = iter(train_loader_T1_pre)\n",
    "           \n",
    "    while step < len(train_loader_T1_pre):\n",
    "        step += 1\n",
    "        inputs_T1_pre, labels = next(iter_T1_pre)\n",
    "        inputs_T1_pre = inputs_T1_pre.to(device)\n",
    "        one_hot_label = np.eye(2)[np.array(labels,dtype=\"int\")]\n",
    "        one_hot_label = torch.tensor(one_hot_label)\n",
    "        optimizer.zero_grad()\n",
    "        joint_embedding, out, predict = model(inputs_T1_pre)\n",
    "        one_hot_label = one_hot_label.type_as(out).to(device)\n",
    "        loss_1 = loss_function(out, one_hot_label)\n",
    "\n",
    "        anchor = 0 \n",
    "        positive = [i for i, x in enumerate(labels) if x == 1]\n",
    "        negative = [i for i, x in enumerate(labels) if x == 0]\n",
    "        if not positive or not negative:\n",
    "            continue\n",
    "        loss = loss_1\n",
    "        for i in positive:\n",
    "            for j in negative:\n",
    "                loss += triplet_loss(0*joint_embedding[0,:], joint_embedding[i,:], joint_embedding[j,:])\n",
    "        loss.backward()\n",
    "        _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds_T1_pre) // train_loader_T1_pre.batch_size\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            num_correct = 0.0\n",
    "            metric_count = 0\n",
    "            pred_list = []\n",
    "            true_list = []\n",
    "            predicted_list=[]\n",
    "            prediction_probablity=[]\n",
    "            label_list = []\n",
    "            val_total=0\n",
    "            val_correct = 0\n",
    "            \n",
    "            iter_T1_pre = iter(val_loader_T1_pre)\n",
    "            step = 0\n",
    "            while step < len(val_loader_T1_pre):\n",
    "                step += 1\n",
    "                val_images_T1_pre, val_labels = next(iter_T1_pre)\n",
    "                val_images_T1_pre = val_images_T1_pre.to(device)\n",
    "                _, out,predict = model(val_images_T1_pre)\n",
    "                _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "                predicted_list.append(predicted.cpu().numpy())\n",
    "                predicted_2 = predict.detach().cpu().numpy()\n",
    "                prediction_prob = predicted_2[:,1].tolist()\n",
    "                prediction_probablity.extend(prediction_prob)\n",
    "                label_list.extend(val_labels.cpu().numpy().tolist())\n",
    "                val_total += val_labels.size(0)\n",
    "                val_correct += (predicted == val_labels).sum().item()\n",
    "            \n",
    "            \n",
    "            Accuracy = val_correct/val_total\n",
    "            y=np.array(label_list)\n",
    "            false_positive_rate, recall, thresholds = roc_curve(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "            roc_auc = auc(false_positive_rate, recall)\n",
    "            auprc = average_precision_score(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "            \n",
    "            if roc_auc > best_AUC:\n",
    "                best_AUC = roc_auc\n",
    "                torch.save(model.state_dict(), \"Models_saved-copy3-pre-Medcam/State_checkpoints_{}.thr\".format(epoch))\n",
    "                torch.save(model, \"Models_saved-copy3-pre-Medcam/Model_checkpoints_{}.thr\".format(epoch))\n",
    "            print(\"AUC: {} , Accuracy: {}, AUPRC: {}\".format(roc_auc, Accuracy, auprc))\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_AUC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f68ee69315dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_AUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_AUC' is not defined"
     ]
    }
   ],
   "source": [
    "best_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256, 44])\n",
      "x shape is : torch.Size([1, 1, 256, 256, 44])\n",
      "module_pos, module conv0 Conv3d(1, 32, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "module_pos, module norm0 BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "module_pos, module relu0 ReLU()\n",
      "module_pos, module pool0 MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "module_pos, module denseblock1 _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(48, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "module_pos, module transition1 _Transition(\n",
      "  (norm): BatchNorm3d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (conv): Conv3d(80, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "module_pos, module denseblock2 _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(40, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(56, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(72, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(88, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(104, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(120, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "module_pos, module transition2 _Transition(\n",
      "  (norm): BatchNorm3d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (conv): Conv3d(136, 68, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "module_pos, module denseblock3 _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(68, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(84, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(100, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(116, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(132, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(148, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(148, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(164, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(164, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(180, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(196, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(212, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(212, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(228, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(244, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_pos, module transition3 _Transition(\n",
      "  (norm): BatchNorm3d(260, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (conv): Conv3d(260, 130, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  (pool): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "module_pos, module denseblock4 _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(130, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(146, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(146, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(162, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(178, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(178, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(194, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(194, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(210, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(210, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(226, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (layers): Sequential(\n",
      "      (norm1): BatchNorm3d(242, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU()\n",
      "      (conv1): Conv3d(242, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU()\n",
      "      (conv2): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "module_pos, module norm5 BatchNorm3d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "got our interested layer: norm5 BatchNorm3d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "conv_output, x shape:  torch.Size([1, 258, 8, 8, 1]) torch.Size([1, 258, 8, 8, 1])\n",
      "conv_output, x  shape:  torch.Size([1, 258, 8, 8, 1]) torch.Size([1, 258, 8, 8, 1])\n",
      "x  shape:  torch.Size([1, 258, 8, 8, 1])\n",
      "final output x:  torch.Size([1, 2])\n",
      "conv_output, model_output shape:  torch.Size([1, 258, 8, 8, 1]) torch.Size([1, 2])\n",
      "one_hot_output shape:  torch.Size([1, 2])\n",
      "target class is: tensor(1)\n",
      "conv_output, guided_gradients are  torch.Size([1, 258, 8, 8, 1]) (258, 8, 8, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (8,8) doesn't match the broadcast shape (8,8,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-e1ef6f237782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_T1_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# cam: (224, 224)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Grad cam completed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-6f7b36541b54>\u001b[0m in \u001b[0;36mgenerate_cam\u001b[0;34m(self, input_image, target_class)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Multiply each weight with its conv output and then, sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mcam\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Normalize between 0-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (8,8) doesn't match the broadcast shape (8,8,8)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ImageDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate, Resize, ScaleIntensity, EnsureType\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((256,256,44)), RandRotate(range_x=0.02, range_y=0.02, range_z=0.02, prob=0.5), EnsureType()])\n",
    "val_transforms = Compose([ScaleIntensity(), AddChannel(), Resize((256,256,44)), EnsureType()])\n",
    "\n",
    "#### ======================================= T1 pre ===============================================\n",
    "# Define image dataset, data loader\n",
    "check_ds_T1_pre = ImageDataset(image_files=images_T1_pre_train, labels=labels_train, transform=train_transforms)\n",
    "check_loader_T1_pre = DataLoader(check_ds_T1_pre, batch_size=1, num_workers=2)# , pin_memory=torch.cuda.is_available())\n",
    "# create a training data loader\n",
    "train_ds_T1_pre = ImageDataset(image_files=images_T1_pre_train, labels=labels_train, transform=train_transforms)\n",
    "train_loader_T1_pre = DataLoader(train_ds_T1_pre, batch_size=1, shuffle=False, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "#create a validation data loader\n",
    "val_ds_T1_pre = ImageDataset(image_files=images_T1_pre_test, labels=labels_test, transform=val_transforms)\n",
    "val_loader_T1_pre = DataLoader(val_ds_T1_pre, batch_size=1, num_workers=2)#, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Create DenseNet121, CrossEntropyLoss and Adam optimizer\n",
    "device = torch.device(14 if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=2)# .to(device)\n",
    "model.eval()\n",
    "iter_T1_pre = iter(train_loader_T1_pre)\n",
    "step = 0\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "\n",
    "while step < len(train_loader_T1_pre):\n",
    "    step += 1\n",
    "    inputs_T1_pre, labels = next(iter_T1_pre)\n",
    "    inputs_T1_pre = inputs_T1_pre# .to(device)\n",
    "    one_hot_label = np.eye(2)[np.array(labels,dtype=\"int\")]\n",
    "    one_hot_label = torch.tensor(one_hot_label)\n",
    "    optimizer.zero_grad()\n",
    "    joint_embedding, out, predict = model(inputs_T1_pre)\n",
    "    print(inputs_T1_pre.shape)\n",
    "    \n",
    "    gcv2 = GradCam(model, target_layer='norm5')\n",
    "    \n",
    "    # Generate cam mask\n",
    "    target_class = labels[0]\n",
    "    \n",
    "    cam = gcv2.generate_cam(inputs_T1_pre, target_class)  # cam: (224, 224)\n",
    "    print('Grad cam completed')\n",
    "\n",
    "    input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for module_pos, module in model.features._modules.items():\n",
    "#     print(module_pos, module)\n",
    "#     if module_pos == 'norm5':\n",
    "#         print('fefe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU\n",
    "\n",
    "class GuidedBackprop():\n",
    "    \"\"\"\n",
    "       Produces gradients generated with guided back propagation from the given image\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        self.forward_relu_outputs = []\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "        self.update_relus()\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.features._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def update_relus(self):\n",
    "        \"\"\"\n",
    "            Updates relu activation functions so that\n",
    "                1- stores output in forward pass\n",
    "                2- imputes zero for gradient values that are less than zero\n",
    "        \"\"\"\n",
    "        def relu_backward_hook_function(module, grad_in, grad_out):\n",
    "            \"\"\"\n",
    "            If there is a negative gradient, change it to zero\n",
    "            \"\"\"\n",
    "            # Get last forward output\n",
    "            corresponding_forward_output = self.forward_relu_outputs[-1]\n",
    "            corresponding_forward_output[corresponding_forward_output > 0] = 1\n",
    "            modified_grad_out = corresponding_forward_output * torch.clamp(grad_in[0], min=0.0)\n",
    "            del self.forward_relu_outputs[-1]  # Remove last forward output\n",
    "            return (modified_grad_out,)\n",
    "\n",
    "        def relu_forward_hook_function(module, ten_in, ten_out):\n",
    "            \"\"\"\n",
    "            Store results of forward pass\n",
    "            \"\"\"\n",
    "            self.forward_relu_outputs.append(ten_out)\n",
    "\n",
    "        # Loop through layers, hook up ReLUs\n",
    "        for pos, module in self.model.features._modules.items():\n",
    "            if isinstance(module, ReLU):\n",
    "                module.register_backward_hook(relu_backward_hook_function)\n",
    "                module.register_forward_hook(relu_forward_hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class):\n",
    "        # Forward pass\n",
    "        model_output = self.model(input_image)\n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "        # Target for backprop\n",
    "        one_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()\n",
    "        one_hot_output[0][target_class] = 1\n",
    "        # Backward pass\n",
    "        model_output.backward(gradient=one_hot_output)\n",
    "        # Convert Pytorch variable to numpy array\n",
    "        # [0] to get rid of the first channel (1,3,224,224)\n",
    "        gradients_as_arr = self.gradients.data.numpy()[0]\n",
    "        return gradients_as_arr\n",
    "\n",
    "\n",
    "def guided_grad_cam(grad_cam_mask, guided_backprop_mask):\n",
    "    \"\"\"\n",
    "        Guided grad cam is just pointwise multiplication of cam mask and\n",
    "        guided backprop mask\n",
    "    Args:\n",
    "        grad_cam_mask (np_arr): Class activation map mask\n",
    "        guided_backprop_mask (np_arr):Guided backprop mask\n",
    "    \"\"\"\n",
    "    cam_gb = np.multiply(grad_cam_mask, guided_backprop_mask)\n",
    "    return cam_gb\n",
    "\n",
    "class CamExtractor():\n",
    "    \"\"\"\n",
    "        Extracts cam features from the model\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward_pass_on_convolutions(self, x):  # x: torch.Size([1, 3, 224, 224])\n",
    "        \"\"\"\n",
    "            Does a forward pass on convolutions, hooks the function at given layer\n",
    "        \"\"\"\n",
    "        print('x shape is :', x.shape)\n",
    "        conv_output = None\n",
    "        for module_pos, module in self.model.features._modules.items():\n",
    "            print('module_pos, module', module_pos, module)\n",
    "            x = module(x)  # Forward\n",
    "#             if int(module_pos) == self.target_layer:\n",
    "            if module_pos == self.target_layer:\n",
    "                print('got our interested layer:', module_pos, module)\n",
    "                x.register_hook(self.save_gradient)\n",
    "                conv_output = x  # Save the convolution output on that layer\n",
    "        print('conv_output, x shape: ', conv_output.shape, x.shape)\n",
    "        return conv_output, x   #  torch.Size([1, 256, 13, 13]) torch.Size([1, 256, 6, 6])\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        \"\"\"\n",
    "            Does a full forward pass on the model\n",
    "        \"\"\"\n",
    "        # Forward pass on the convolutions\n",
    "        conv_output, x = self.forward_pass_on_convolutions(x)\n",
    "        print('conv_output, x  shape: ', conv_output.shape, x.shape)\n",
    "#         x = x.view(x.size(0), -1)  # Flatten  #  after: torch.Size([1, 9216]), 9126=256x6x6\n",
    "        print('x  shape: ',  x.shape)\n",
    "        # Forward pass on the classifier\n",
    "        #### theirs .....\n",
    "#         x = self.model.classifier(x)   # after: torch.Size([1, 1000])  \n",
    "        #### mine .....\n",
    "        for module_pos, module in self.model.class_layers._modules.items():\n",
    "            x = module(x)\n",
    "        print('final output x: ', x.shape)\n",
    "        return conv_output, x\n",
    "\n",
    "\n",
    "class GradCam():\n",
    "    \"\"\"\n",
    "        Produces class activation map\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        # Define extractor\n",
    "        self.extractor = CamExtractor(self.model, target_layer)\n",
    "\n",
    "    def generate_cam(self, input_image, target_class=None):\n",
    "        # Full forward pass\n",
    "        # conv_output is the output of convolutions at specified layer\n",
    "        # model_output is the final output of the model (1, 1000)\n",
    "        conv_output, model_output = self.extractor.forward_pass(input_image)  # torch.Size([1, 256, 13, 13]) torch.Size([1, 1000])\n",
    "        if target_class is None:\n",
    "            target_class = np.argmax(model_output.data.numpy())\n",
    "        # Target for backprop\n",
    "        print('conv_output, model_output shape: ', conv_output.shape, model_output.shape) \n",
    "        one_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()  #  torch.Size([1, 1000])\n",
    "        print('one_hot_output shape: ', one_hot_output.shape)\n",
    "        one_hot_output[0][target_class] = 1\n",
    "        print('target class is:', target_class)  # target_class = 56\n",
    "        # Zero grads\n",
    "        self.model.features.zero_grad()\n",
    "#         self.model.classifier.zero_grad()\n",
    "        self.model.class_layers.zero_grad()\n",
    "\n",
    "        # Backward pass with specified target\n",
    "        model_output.backward(gradient=one_hot_output, retain_graph=True)\n",
    "        # Get hooked gradients\n",
    "        guided_gradients = self.extractor.gradients.data.numpy()[0]\n",
    "        # Get convolution outputs\n",
    "        print('conv_output, guided_gradients are ',conv_output.shape, guided_gradients.shape)\n",
    "        target = conv_output.data.numpy()[0]\n",
    "        # Get weights from gradients\n",
    "        weights = np.mean(guided_gradients, axis=(1, 2))  # Take averages for each gradient\n",
    "        # Create empty numpy array for cam\n",
    "#         cam = np.ones(target.shape[1:], dtype=np.float32)\n",
    "        cam = np.ones(target.shape[1:-1], dtype=np.float32)\n",
    "        # Multiply each weight with its conv output and then, sum\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))  # Normalize between 0-1\n",
    "        cam = np.uint8(cam * 255)  # Scale between 0-255 to visualize\n",
    "        print('cam is:', cam.shape, cam.dtype)\n",
    "        cam = np.uint8(Image.fromarray(cam).resize((input_image.shape[2],\n",
    "                       input_image.shape[3]), Image.ANTIALIAS))\n",
    "        # ^ I am extremely unhappy with this line. Originally resizing was done in cv2 which\n",
    "        # supports resizing numpy matrices, however, when I moved the repository to PIL, this\n",
    "        # option is out of the window. So, in order to use resizing with ANTIALIAS feature of PIL,\n",
    "        # I briefly convert matrix to PIL image and then back.\n",
    "        # If there is a more beautiful way, send a PR.\n",
    "        return cam\n",
    "\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.cm as mpl_color_map\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "def convert_to_grayscale(im_as_arr):\n",
    "    \"\"\"\n",
    "        Converts 3d image to grayscale\n",
    "    Args:\n",
    "        im_as_arr (numpy arr): RGB image with shape (D,W,H)\n",
    "    returns:\n",
    "        grayscale_im (numpy_arr): Grayscale image with shape (1,W,D)\n",
    "    \"\"\"\n",
    "    grayscale_im = np.sum(np.abs(im_as_arr), axis=0)\n",
    "    im_max = np.percentile(grayscale_im, 99)\n",
    "    im_min = np.min(grayscale_im)\n",
    "    grayscale_im = (np.clip((grayscale_im - im_min) / (im_max - im_min), 0, 1))\n",
    "    grayscale_im = np.expand_dims(grayscale_im, axis=0)\n",
    "    return grayscale_im\n",
    "\n",
    "\n",
    "def save_gradient_images(gradient, file_name):\n",
    "    \"\"\"\n",
    "        Exports the original gradient image\n",
    "    Args:\n",
    "        gradient (np arr): Numpy array of the gradient with shape (3, 224, 224)\n",
    "        file_name (str): File name to be exported\n",
    "    \"\"\"\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    # Normalize\n",
    "    gradient = gradient - gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    # Save image\n",
    "    path_to_file = os.path.join('results', file_name + '.jpg')\n",
    "    save_image(gradient, path_to_file)\n",
    "\n",
    "\n",
    "def save_class_activation_images(org_img, activation_map, file_name):\n",
    "    \"\"\"\n",
    "        Saves cam activation map and activation map on the original image\n",
    "    Args:\n",
    "        org_img (PIL img): Original image\n",
    "        activation_map (numpy arr): Activation map (grayscale) 0-255\n",
    "        file_name (str): File name of the exported image\n",
    "    \"\"\"\n",
    "    if not os.path.exists('../results'):\n",
    "        os.makedirs('../results')\n",
    "    # Grayscale activation map\n",
    "    heatmap, heatmap_on_image = apply_colormap_on_image(org_img, activation_map, 'hsv')\n",
    "    # Save colored heatmap\n",
    "    path_to_file = os.path.join('results', file_name+'_Cam_Heatmap.png')\n",
    "    save_image(heatmap, path_to_file)\n",
    "    # Save heatmap on iamge\n",
    "    path_to_file = os.path.join('results', file_name+'_Cam_On_Image.png')\n",
    "    save_image(heatmap_on_image, path_to_file)\n",
    "    # SAve grayscale heatmap\n",
    "    path_to_file = os.path.join('results', file_name+'_Cam_Grayscale.png')\n",
    "    save_image(activation_map, path_to_file)\n",
    "\n",
    "\n",
    "def apply_colormap_on_image(org_im, activation, colormap_name):\n",
    "    \"\"\"\n",
    "        Apply heatmap on image\n",
    "    Args:\n",
    "        org_img (PIL img): Original image\n",
    "        activation_map (numpy arr): Activation map (grayscale) 0-255\n",
    "        colormap_name (str): Name of the colormap\n",
    "    \"\"\"\n",
    "    # Get colormap\n",
    "    color_map = mpl_color_map.get_cmap(colormap_name)\n",
    "    no_trans_heatmap = color_map(activation)\n",
    "    # Change alpha channel in colormap to make sure original image is displayed\n",
    "    heatmap = copy.copy(no_trans_heatmap)\n",
    "    heatmap[:, :, 3] = 0.4\n",
    "    heatmap = Image.fromarray((heatmap*255).astype(np.uint8))\n",
    "    no_trans_heatmap = Image.fromarray((no_trans_heatmap*255).astype(np.uint8))\n",
    "\n",
    "    # Apply heatmap on iamge\n",
    "    heatmap_on_image = Image.new(\"RGBA\", org_im.size)\n",
    "    heatmap_on_image = Image.alpha_composite(heatmap_on_image, org_im.convert('RGBA'))\n",
    "    heatmap_on_image = Image.alpha_composite(heatmap_on_image, heatmap)\n",
    "    return no_trans_heatmap, heatmap_on_image\n",
    "\n",
    "\n",
    "def save_image(im, path):\n",
    "    \"\"\"\n",
    "        Saves a numpy matrix of shape D(1 or 3) x W x H as an image\n",
    "    Args:\n",
    "        im_as_arr (Numpy array): Matrix of shape DxWxH\n",
    "        path (str): Path to the image\n",
    "    \"\"\"\n",
    "    if isinstance(im, np.ndarray):\n",
    "        if len(im.shape) == 2:\n",
    "            im = np.expand_dims(im, axis=0)\n",
    "        if im.shape[0] == 1:\n",
    "            # Converting an image with depth = 1 to depth = 3, repeating the same values\n",
    "            # For some reason PIL complains when I want to save channel image as jpg without\n",
    "            # additional format in the .save()\n",
    "            im = np.repeat(im, 3, axis=0)\n",
    "            # Convert to values to range 1-255 and W,H, D\n",
    "        if im.shape[0] == 3:\n",
    "            im = im.transpose(1, 2, 0) * 255\n",
    "        im = Image.fromarray(im.astype(np.uint8))\n",
    "    im.save(path)\n",
    "\n",
    "\n",
    "def preprocess_image(pil_im, resize_im=True):\n",
    "    \"\"\"\n",
    "        Processes image for CNNs\n",
    "    Args:\n",
    "        PIL_img (PIL_img): Image to process\n",
    "        resize_im (bool): Resize to 224 or not\n",
    "    returns:\n",
    "        im_as_var (torch variable): Variable that contains processed float tensor\n",
    "    \"\"\"\n",
    "    # mean and std list for channels (Imagenet)\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    # Resize image\n",
    "    if resize_im:\n",
    "        pil_im.thumbnail((512, 512))\n",
    "    im_as_arr = np.float32(pil_im)\n",
    "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
    "    # Normalize the channels\n",
    "    for channel, _ in enumerate(im_as_arr):\n",
    "        im_as_arr[channel] /= 255\n",
    "        im_as_arr[channel] -= mean[channel]\n",
    "        im_as_arr[channel] /= std[channel]\n",
    "    # Convert to float tensor\n",
    "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
    "    im_as_ten.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    im_as_ten.requires_grad = True\n",
    "    im_as_var = im_as_ten\n",
    "    return im_as_var\n",
    "\n",
    "\n",
    "def recreate_image(im_as_var):\n",
    "    \"\"\"\n",
    "        Recreates images from a torch variable, sort of reverse preprocessing\n",
    "    Args:\n",
    "        im_as_var (torch variable): Image to recreate\n",
    "    returns:\n",
    "        recreated_im (numpy arr): Recreated image in array\n",
    "    \"\"\"\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    recreated_im = copy.copy(im_as_var.data.numpy()[0])\n",
    "    for c in range(3):\n",
    "        recreated_im[c] /= reverse_std[c]\n",
    "        recreated_im[c] -= reverse_mean[c]\n",
    "    recreated_im[recreated_im > 1] = 1\n",
    "    recreated_im[recreated_im < 0] = 0\n",
    "    recreated_im = np.round(recreated_im * 255)\n",
    "\n",
    "    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
    "    return recreated_im\n",
    "\n",
    "\n",
    "def get_positive_negative_saliency(gradient):\n",
    "    \"\"\"\n",
    "        Generates positive and negative saliency maps based on the gradient\n",
    "    Args:\n",
    "        gradient (numpy arr): Gradient of the operation to visualize\n",
    "    returns:\n",
    "        pos_saliency ( )\n",
    "    \"\"\"\n",
    "    pos_saliency = (np.maximum(0, gradient) / gradient.max())\n",
    "    neg_saliency = (np.maximum(0, -gradient) / -gradient.min())\n",
    "    return pos_saliency, neg_saliency\n",
    "\n",
    "\n",
    "def get_example_params(example_index):\n",
    "    \"\"\"\n",
    "        Gets used variables for almost all visualizations, like the image, model etc.\n",
    "    Args:\n",
    "        example_index (int): Image id to use from examples\n",
    "    returns:\n",
    "        original_image (numpy arr): Original image read from the file\n",
    "        prep_img (numpy_arr): Processed image\n",
    "        target_class (int): Target class for the image\n",
    "        file_name_to_export (string): File name to export the visualizations\n",
    "        pretrained_model(Pytorch model): Model to use for the operations\n",
    "    \"\"\"\n",
    "    # Pick one of the examples\n",
    "    example_list = (('input_images/snake.jpg', 56),\n",
    "                    ('input_images/cat_dog.png', 243),\n",
    "                    ('input_images/spider.png', 72))\n",
    "    img_path = example_list[example_index][0]\n",
    "    target_class = example_list[example_index][1]\n",
    "    file_name_to_export = img_path[img_path.rfind('/')+1:img_path.rfind('.')]\n",
    "    # Read image\n",
    "    original_image = Image.open(img_path).convert('RGB')\n",
    "    # Process image\n",
    "    prep_img = preprocess_image(original_image)\n",
    "\n",
    "    print(\"program flow\")\n",
    "\n",
    "    # Define model\n",
    "    pretrained_model = models.alexnet(pretrained=True)\n",
    "    return (original_image,\n",
    "            prep_img,\n",
    "            target_class,\n",
    "            file_name_to_export,\n",
    "            pretrained_model)\n",
    "\n",
    "\n",
    "def normalize_gradient_image(gradient):\n",
    "    gradient = gradient - gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = inputs_T1_pre\n",
    "# for module_pos, module in model.features._modules.items():\n",
    "#     print('module_pos, module', module_pos, module)\n",
    "#     x = module(x)\n",
    "# #     print(x.shape)\n",
    "    \n",
    "    \n",
    "# for module_pos, module in model.class_layers._modules.items():\n",
    "#     print('======>', module_pos)\n",
    "#     x = module(x)\n",
    "    \n",
    "#     print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
